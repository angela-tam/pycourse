{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## LESSON 5: USING PYTHON FOR BASIC NEUROIMAGING PROCESSES AND ANALYSES ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''In this lesson, you will learn how to interact with neuroimages using Python. You will also \n",
    "learn tools to efficiently analyze and modify images. Finally, you'll learn how to use python \n",
    "to interact with already existing neuroimaging software.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note -- in order to complete this lesson, you will have to ensure all of the proper libaries\n",
    "# are installed. You may need to install the following libraries \n",
    "\n",
    "# nibabel\n",
    "# nilearn\n",
    "# sklearn\n",
    "\n",
    "# For nilearn, you will need to install it directly from a certain channel called conda-forge.\n",
    "# You can do so like this:\n",
    "\n",
    "# conda install -c conda-forge nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "import nibabel as ni\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The first thing we should to is open up an image so we can get familiar with its anatomy.\n",
    "# For this, we will use the library nibabel. Nibabel's purpose is to help you take neuroimages\n",
    "# of various formats and load them them into your python workspace.\n",
    "\n",
    "# A very handy utility is ni.load(). This function is pretty good about detecting what kind of\n",
    "# image you're loading. It will accept Niftis, ANALYSE images (i.e. hdr/img files), Minc images\n",
    "# and more.\n",
    "\n",
    "cwd = os.getcwd()\n",
    "img = ni.load(\n",
    "        os.path.join(cwd,'stuff/nan_snorm_002-S-4229_18F-AV1451_2016-02-10_P4_I635352.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now that the image has been loaded, we can interrogate several of its properties. For \n",
    "# example, here is the image affine\n",
    "\n",
    "img.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This particular image does not have a header, but if it did, we can access it easily:\n",
    "img.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here is its shape. The shape represents the number of voxels in each dimension. This is a 3D\n",
    "# image\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally there's the image data itself. An image is simply a matrix of values. In this case, \n",
    "# each value is represented as a voxel -- a 3D cube containing information about the image. \n",
    "# The values within the image depends on what type of image it is. This is a PET image, which\n",
    "# has been intensity-normalized. Therefore, each value (voxel) in the matrix represents whats\n",
    "# called an SUVR -- its a primitive ratio of PET signal to noise signal. Let's have a look\n",
    "# at the data\n",
    "\n",
    "dat = img.get_data()\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We're only gettings a small snapshot of the image here -- Python will not display all of \n",
    "# the values. Why not? Well, lets think about how many values there really are:\n",
    "a,b,c = img.shape\n",
    "a*b*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Over 7 million!! There's no reason for Python to display all of these values because it would\n",
    "# not be human readable (ahem, matlab...). We'll come back to this conundrum later. First, lets\n",
    "# examine what kind of object this image data is\n",
    "type(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is an object we haven't run into yet. Luckily, its not very different from objects we \n",
    "# have encountered. A numpy n-dimensional array behaves quite similarly to a list, and you can\n",
    "# think of it as an optimized lists with many features. Lets have a look:\n",
    "lst = [1,2,3]\n",
    "arr = np.array(lst)\n",
    "print(lst,'\\n',arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can already see the difference in presentation between a list and an np.array -- the \n",
    "# values are not comma-separated. However, you cannot build an np.array from scratch like you\n",
    "# can a list\n",
    "new_arr = [1 2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python won't recognize it. Instead, you need to convert an existing sequences as we did above,\n",
    "# or, use a numpy function to build it. There are a few ways to do this\n",
    "\n",
    "# create a 2 x 2 array of random values\n",
    "new_arr = np.ndarray((2,2),dtype=int)\n",
    "print(new_arr,'\\n')\n",
    "\n",
    "# create an ordered sequence of integers with a length 8\n",
    "new_arr = np.arange((8))\n",
    "print(new_arr,'\\n')\n",
    "\n",
    "# same as above but shaped into a 2x4 matrix\n",
    "new_arr = np.arange((8)).reshape((2,4)) # notice this takes a tuple containing the shape as\n",
    "                                        # an argument\n",
    "print(new_arr,'\\n')\n",
    "\n",
    "# create a 3x2x2 array of 0s\n",
    "new_arr = np.zeros((3,2,2))\n",
    "\n",
    "print(new_arr,'\\n')\n",
    "\n",
    "# create an empty array 3x3 array\n",
    "new_arr = np.empty((3,3))\n",
    "print(new_arr,'\\n')\n",
    "\n",
    "# create an len(10) array of 9s\n",
    "new_arr = np.full(10,9,int)\n",
    "print(new_arr,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also use most of these commands to generate an array that has the same shape as an\n",
    "# existing array. For example, lets say we wanted to make an array the same sizes as our image\n",
    "# data, but we wanted it filled with 0s...\n",
    "new_arr = np.zeros_like(dat)\n",
    "new_arr.shape\n",
    "print(new_arr[75,75,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.arrays can be indexed just like lists.\n",
    "new_arr = np.arange(10)\n",
    "print(new_arr)\n",
    "print(new_arr[4])\n",
    "print(new_arr[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for arrays with multiple dimensions, its still quite easy to index and slice. Lets take our\n",
    "# image data for instance. Lets say we wanted to look at every value in x plane at y,z\n",
    "# coordinates 70,75\n",
    "\n",
    "dat[:,70,75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# But you have to be careful -- like lists, arrays are mutable\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = a\n",
    "print('here is a',a)\n",
    "print('here is b, which is set as equal to a',b)\n",
    "b[0] = 10\n",
    "print('here is a after changing b',a)\n",
    "print('here is b after changing b',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# However, like Series', np.arrays have all sorts of tremendously useful methods and attributes\n",
    "# that help to perform efficient operations on arrays and matrices. This is very important \n",
    "# given that, as we have already demosnstrated, neuroimages are not small.\n",
    "\n",
    "# Lets make an arbitrary 4x4 matrix and show off just a few of these features.\n",
    "\n",
    "mtx = np.arange(16).reshape((4,4))\n",
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can easily manipulate matrices with regular arithmetic\n",
    "print(mtx + 3,'\\n')\n",
    "print(mtx / 2, '\\n')\n",
    "\n",
    "# Or matrix math\n",
    "print(mtx * [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also get quick descriptives\n",
    "print('mean:',mtx.mean())\n",
    "print('std:',mtx.std())\n",
    "print('sum:',mtx.sum())\n",
    "print('\\n')\n",
    "\n",
    "# Or get information about the mins and maxs and their index\n",
    "print('min:',mtx.min())\n",
    "print('index of min:',mtx.argmin())\n",
    "print('max:',mtx.max())\n",
    "print('index of max:',mtx.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can easily coerce np.arrays to different data types\n",
    "print(mtx.astype(int),'\\n')\n",
    "print(mtx.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For symettrical matrices, there are also plenty of useful commands for extracting certain\n",
    "# parts of the matrix.\n",
    "\n",
    "# Get just the diagonal\n",
    "print(mtx.diagonal())\n",
    "# change diagnoal to ones\n",
    "newmtx = deepcopy(mtx)\n",
    "diag_ix = np.diag_indices_from(mtx)\n",
    "newmtx[diag_ix] = np.ones(4)\n",
    "newmtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets quickly break down how that worked, because its shows off some very nice features of\n",
    "# these arrays, namely their indexing\n",
    "\n",
    "# We first obtained the indices of each value within the diagonal of the matrix with a\n",
    "# specialized function. Because the matrix (np.array) is 2d, the indices are also 2D. Have a\n",
    "# look\n",
    "diag_ix = np.diag_indices_from(mtx)\n",
    "diag_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So the indices come in the form of two arrays. One array carries the x-indices and the other\n",
    "# array carries the y-indices. These two arrays are contained within a tuple.\n",
    "\n",
    "# A nice feature of np.ndarrays is that you can index with tuples. When I index using this \n",
    "# tuple of arrays, Python will return the value at the corresponding coordinates, which in this\n",
    "# case are 0,0  1,1  2,2  and 3,3\n",
    "\n",
    "# Have a look. \n",
    "\n",
    "print('here is the matrix: \\n',mtx,'\\n')\n",
    "print('and here are the values at the indices we passed:',mtx[diag_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For example, if I wanted to view just the values at coordiantes 0,3 and 2,2, I could do\n",
    "# so like this:\n",
    "mtx[([0,2],[3,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And changing the values is simple. We can change only the values at the index we pass. In\n",
    "# the case above, we changed them to ones. Because there are four values to change, we passed\n",
    "# an array of four 1s. \n",
    "\n",
    "newmtx = deepcopy(mtx)\n",
    "ones = np.ones(4)\n",
    "print('here is the input',ones)\n",
    "newmtx[diag_ix] = ones\n",
    "print('and here is the result \\n', newmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using a similar approach, we can easily extract just the lower triangle of a matrix\n",
    "a,b = mtx.shape\n",
    "lo_tri = np.tril_indices(a)\n",
    "print('here is the matrix \\n',mtx,'\\n')\n",
    "print('here are the indices of the triangle \\n',lo_tri)\n",
    "print('here are the values at that index',mtx[lo_tri],'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and if we want to change the lower triangle to 0s (but then retain the diagonal as ones)...\n",
    "\n",
    "# exchange values at the indices of the lower triangle with an array of zeros with the same\n",
    "# length as the number of values in the lower triangle\n",
    "newmtx[lo_tri] = np.zeros_like(lo_tri[0])\n",
    "# add back the ones at the diagonal\n",
    "newmtx[diag_ix] = ones\n",
    "print('et voila! Our new matrix: \\n',newmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matrices can be easily reshaped to other shapes, as long as the dimensions are\n",
    "# interchangeable with the current matrix shape. \n",
    "\n",
    "# Here are a few ways we could reshape our current array\n",
    "print(mtx.reshape(8,2),'\\n')\n",
    "print(mtx.reshape(2,2,2,2),'\\n')\n",
    "print(mtx.reshape(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And matrices can be very easily transposed\n",
    "print('original: \\n',mtx,'\\n')\n",
    "print('tranposed: \\n',mtx.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And conveniently, we can always convert an array back to a list if needed. Although notice\n",
    "# what the output looks like\n",
    "mtx.tolist()\n",
    "\n",
    "# Our np.array was a 4x4 matrix. So rather than being a list of 16 values, we have a list of \n",
    "# four lists, each containing four values. If you wanted to create a 2D np.array from a list,\n",
    "# this is how you would construct the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or, if you'd rather work with pandas, you can easily convert a 2D matrix to a pandas \n",
    "# DataFrame\n",
    "pandas.DataFrame(mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are other neat tricks with indexing using booleans\n",
    "newmtx = deepcopy(mtx)\n",
    "print(mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First of all, np.arrays respond to boolean statements. Have a look\n",
    "newmtx>7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here's another example\n",
    "newmtx == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, look what happens when we index the matrix with a boolean. If we wanted to, for example,\n",
    "# return only items from the matrix greater than 7, we would index the matrix with a boolean\n",
    "# matrix. We just saw how we can make a boolean matrix by just creating a boolean statement\n",
    "# that includes a matrix in it. Now we can use that to index!\n",
    "newmtx[newmtx>7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notice how the numbers that are returned are only those that are True in the output three\n",
    "# cells up!\n",
    "\n",
    "# We can also change matrix values in this way\n",
    "newmtx[newmtx>7] = 0\n",
    "newmtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WAAAAIIIIIIITTTTTT!!!!!!!!!!!!!!!!!!\n",
    "# I know what you're thinking. \"Hey, I thought this was Lesson was supposed to be about \n",
    "# Neuroimages.\" Well, ultimately, in Python, neuroimages are just matrices of values in the \n",
    "# form of np.arrays! So everything you're learning here can be applied easily to an image. And \n",
    "# we'll be doing just that shortly. However, if you want to be able to manipulate these images, \n",
    "# you must be comfortable with np.arrays.\n",
    "\n",
    "# So, let's complete a couple of basic exercises to make sure you're warmed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## EXERCISES I ###########\n",
    "\n",
    "## PART A\n",
    "# Create a 3x3x4 matrix of ascending integers and print it\n",
    "\n",
    "## PART B\n",
    "# Take the matrix from part A and modify it so that all odd numbers are set to 0\n",
    "\n",
    "## PART C \n",
    "# Create a 5x5 matrix of 0s. Set all values in the upper triangle of the matrix to 5, and set \n",
    "# the diagonal to ones. Then transpose it.\n",
    "\n",
    "## PART D\n",
    "# Create a large matrix of 0s that spells the word \"Hi\" in ones. Convert the matrix dtype to\n",
    "# int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ANSWERS ARE BELOW\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### ANSWERS TO EXERCISE I ######\n",
    "\n",
    "## PART A\n",
    "# Create a 3x3x4 matrix of ascending integers and print it\n",
    "x_mtx = np.arange(3*3*4).reshape(3,3,4)\n",
    "print(x_mtx,'\\n')\n",
    "\n",
    "## PART B\n",
    "# Take the matrix from part A and modify it so that all odd numbers are set to 0\n",
    "x_mtx[x_mtx%2>0] = 0\n",
    "print(x_mtx,'\\n')\n",
    "\n",
    "## PART C \n",
    "# Create a 5x5 matrix of 0s. Set all values in the upper triangle of the matrix to 5, and set \n",
    "# the diagonal to ones.\n",
    "x2m = np.zeros((5,5))\n",
    "utri = np.triu_indices_from(x2m)\n",
    "diag = np.diag_indices_from(x2m)\n",
    "x2m[utri] = 5\n",
    "x2m[diag] = np.ones(len(diag[0]))\n",
    "# Then transpose\n",
    "print(x2m.transpose(),'\\n')\n",
    "\n",
    "## PART D\n",
    "# Create a large matrix of 0s that spells the word \"Hi\" in ones. Convert the matrix dtype to\n",
    "# int\n",
    "hmtx = np.zeros((5,7))\n",
    "hind = ([0,1,2,3,4,2,0,1,2,3,4,0,4,0,1,2,3,4,0,4],[0,0,0,0,0,1,2,2,2,2,2,4,4,5,5,5,5,5,6,6])\n",
    "hmtx[hind] = 1\n",
    "print(hmtx.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Okay, so now we're comfortable with numpy arrays. But we still have a lingering issue -- \n",
    "# neuroimages are very large arrays. We already showed that an image with 1mm resolution \n",
    "# contains over 7 million values.\n",
    "\n",
    "# Iterating over such a large matrix is very computationally and time intensive. However, there\n",
    "# are little tricks that can help drastically speed up computation of large neuroimages. Let's\n",
    "# explore this a bit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use the timeit magic to track the speed of different operations. Its very easy to use\n",
    "# it looks like this:\n",
    "\n",
    "# %timeit operation to time\n",
    "\n",
    "# As an example...\n",
    "%timeit 50/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets start with a simple example. We'll create a matrix of ones that is the exact size of our\n",
    "# neuroimage\n",
    "ni_1 = np.ones_like(dat)\n",
    "x,y,z = ni_1.shape\n",
    "# Now lets say we want to execute a simple operation -- we want to add +1 to every value. How\n",
    "# would you go about doing that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you didn't know about some of the nifty tricks with numpy, you might try iterating through\n",
    "# all three indices. \n",
    "\n",
    "def iter1(in_mtx):\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            for k in range(z):\n",
    "                in_mtx[i,j,k] +=1\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now lets use timeit to time the speed of this function\n",
    "%timeit iter1(ni_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Holy hell that was SLOW!! over 30s on my machine. Lets compare it to letting numpy do its\n",
    "# own iteration by using built-in numpy functionality\n",
    "%timeit ni_1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On my computer, the average speed for this operation was 12.2 ms, compared to 33.5 seconds. \n",
    "# So.. how much faster was it?\n",
    "print('this was a speed up of %s times!!!'%(round(33500/12.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hopefully you see my point. Using python-friendly language can save you a TON of time. When\n",
    "# you're doing very small operations, you won't notice the speed-up, but when dealing with \n",
    "# much larger computation (such as something related to a neuroimage), the speed up could save\n",
    "# hours!\n",
    "\n",
    "# But of course, sometimes you will need to iterate through values, and when you do,\n",
    "# you should know there are many tools to do it. Some tools are a bit advanced, like numba and\n",
    "# cython, and I will hold off on explaining those tools for now. Instead, I will teach some \n",
    "# more basic tools that will still give you considerable speed advantages. Let's start with\n",
    "# list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List comprehension is a method of iterating through a list, but doing it in one line. Here's\n",
    "# a short example. I will use a traditional For loop and list comprehension to do the same\n",
    "# thing. We will print the squares of integers from 1 to 10\n",
    "\n",
    "# First, the \"traditional way\", using a For loop \n",
    "def lc1(rang):\n",
    "    jnk = []\n",
    "    for x in range(rang):\n",
    "        jnk.append(x**2)\n",
    "    return jnk\n",
    "\n",
    "jnk = lc1(10)\n",
    "print(jnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now I'll do the same thing with list comprehension\n",
    "def lc2(rang):\n",
    "    return [x**2 for x in range(rang)]\n",
    "\n",
    "jnk = lc2(10)\n",
    "print(jnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same output. Lets examine how that works. \n",
    "\n",
    "# Here's the code again\n",
    "[x**2 for x in range(10)]\n",
    "\n",
    "# 1) Notice the entire command is surrounded by square brackets. This is essential.\n",
    "# 2) Lets start at the end. Notice how the end of the line is this\n",
    "\n",
    "# for x in range(10)\n",
    "\n",
    "# Looks exactly like a for loop doesn't it? In a for loop, the For statement goes at the \n",
    "# beginning, and everything else underneath and indented. In list comprehension, the for loop\n",
    "# comes after the operation.\n",
    "# 3) Instead of the operation being underneath the for loop, the operation precedes the for \n",
    "# loop. So,\n",
    "\n",
    "# [x**2 for x in range(10)]\n",
    "\n",
    "# is identical to\n",
    "\n",
    "# for x in range(10):\n",
    "#    x**2\n",
    "\n",
    "# Except its all in one line, and the output is automatically made into a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With small iterables, list comprehension only saves a bit of time\n",
    "# Here is the original way\n",
    "%timeit lc1(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here is the with list comprehension\n",
    "%timeit lc2(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# But its important to know why. List comprehension usually allows for cleaner, simpler code \n",
    "# with less operations, which are themselves optimized. The speed-up above probably comes from \n",
    "# the fact that you are doing one less operation (creating and storing the variable jnk), and \n",
    "# indeed, a clever list comprehension might save even more time by eliminating more superfluous \n",
    "# operations\n",
    "\n",
    "# However, as we'll see below, as your iterables become larger, the speed-up you get from list\n",
    "# comprehension improves dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List comprehension can get quite complicated, as you'll see below. If you're uncomfortable \n",
    "# with the syntax of list comprehension, perhaps you would prefer the map function, which \n",
    "# can accomplish the same thing with different inputs.\n",
    "\n",
    "# The map functions works a bit differently. Map takes two arguments, a function, and an \n",
    "# iterable. An iterable is of course a subscriptable (sequence) object of any type (list, \n",
    "# tuple, np.array, etc). And a function is any python function, including a function you \n",
    "# define. To accomplish the same operation as we did with list comprehension above, it would \n",
    "# look like this:\n",
    "\n",
    "def j_sqr(x):\n",
    "    return x**2\n",
    "\n",
    "list(map(j_sqr,range(10)))\n",
    "\n",
    "# So here, for each item in range(10), we are performing the function j_square using the item\n",
    "# as the argument for j_sqr. Then we are converting the output into a list. So, its doing the\n",
    "# exact same thing as what we did above with a For Loop and list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# However, an advantage to using map is that its FAST! \n",
    "%timeit list(map(j_sqr,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On my computer, I got a nice speed up:\n",
    "print('operation using map was %s times faster than list comprehension'%(42.2/6.57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just remember -- a speed up of six times could be very considerable! If you have a process\n",
    "# that took an hour with list comprehension, replacing with map in this case would reduce it to\n",
    "# <10 minutes\n",
    "\n",
    "# By the way, you might be thinking map() is inconvenient because you must pass a function as \n",
    "# the first argument. It may seem silly to create a new function just to do a simple operation.\n",
    "# Luckily, the lambda function exists exactly for this purpose -- it lets you create a very\n",
    "# quick and simple one-off function. In other words, its a handy way of performing an operation\n",
    "# on an object without having to create a new function. \n",
    "\n",
    "# Here, I'll do the exact same thing as I did above, except rather than defining the j_sqr \n",
    "# function, I'll achieve the same functionality using lambda (I'll explain it after)\n",
    "list(map(lambda x: x**2,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the above example, lambda x: x**2 just means, for every x in an iterable (in this case, \n",
    "# range(10), square x. This is almost like combining list comprehension with map(). It works\n",
    "# like this: lambda [arbitrary variable name]: operation on variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List comprehension, map and lambda can all be made to be much more complicated. They may be\n",
    "# intimidating at first, but they allow for very clean and very efficient code, which is often\n",
    "# what is needed when dealing with neuroimaging data. Importantly, these functions can deal\n",
    "# with multiple arguments or iterables. See below for some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, say you have two lists of values and you want to multiply the values together at each\n",
    "# index. I will demonstrate this using For loops, map, and list comprehension below\n",
    "\n",
    "lst1 = range(10)\n",
    "lst2 = range(10,20)\n",
    "\n",
    "# For Loop\n",
    "nlst = []\n",
    "for i in range(len(lst1)):\n",
    "    x,y = lst1[i],lst2[i]\n",
    "    nlst.append(x*y)\n",
    "print(nlst)\n",
    "\n",
    "# Map\n",
    "nlst = list(map(lambda x,y: x*y, lst1, lst2))\n",
    "print(nlst)\n",
    "\n",
    "# List comprehension (we'll need a new tool for this one)\n",
    "nlst = [x*y for x,y in zip(lst1,lst2)]\n",
    "print(nlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, notice how much more effort and space was necessary for the For Loop in the first\n",
    "# example. Second, notice how list comprehension and map were able to accept multiple arguments\n",
    "# and multiple iterables.\n",
    "\n",
    "# For map, we used lambda to create mini function with two arguments (x and y) and the \n",
    "# operation of that function was to multiply x and y together. Then, using map, we applied that\n",
    "# function to every x,y pair between the two iterables (lst1 and lst2).\n",
    "\n",
    "# For the list comprehension, we define the operation (x*y) first, then we define the arbitrary \n",
    "# variables (x and y), and then explain to which iterables x and y belong to (lst1 and lst2). \n",
    "# However, we had to use a new function, zip, to do this. Zip simply combines the two iterables\n",
    "# so that they are joint by a single index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can take things even further with list comprehension by adding conditionals at the end.\n",
    "# Lets say you only wanted to perform the operation on iterations where x is greater than 4.\n",
    "# This is simple and intuitive with list comprehension\n",
    "[x*y for x,y in zip(lst1,lst2) if x>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now that you've been introduced to these concepts, I will show you how they can be useful for\n",
    "# neuroimages. Let's say you wanted to z-transform an image. You have a mean and SD for every\n",
    "# voxel, and you want to apply those to your image. There are of course many ways to do this\n",
    "# but lets use our new tricks. First, so its easier to see what's going on, I'll create small\n",
    "# 3D matrices to practice on\n",
    "\n",
    "img_x = 2.5 * np.random.rand(4,4,4)\n",
    "img_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And now we'll create some fake means and SDs...\n",
    "means = 2.5 * np.random.rand(4,4,4)\n",
    "sds = 1.5 * np.random.rand(4,4,4)\n",
    "print(means,'\\n \\n \\n',sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the purposes of demonstration, lets first do this using a For Loop\n",
    "def zscore_forloop(mat,means,sds):\n",
    "    x,y,z = mat.shape # get the shape of the input matrix\n",
    "    newmat = np.empty((x,y,z)) # create an empty output matrix of the same dimensions \n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            for k in range(z):\n",
    "                newmat[i,j,k] = (mat[i,j,k] - means[i,j,k]) / sds[i,j,k]\n",
    "\n",
    "    return newmat\n",
    "\n",
    "jnk1 = zscore_forloop(img_x,means,sds)\n",
    "print(jnk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It works, but, like an ogre, its big, ugly and slow! Let's try our new tricks out instead\n",
    "# Here's the same thing with map\n",
    "jnk2 = list(map(lambda i,j,k: (i-j)/k,img_x,means,sds))\n",
    "jnk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And now again with list comprehension\n",
    "jnk3 = [(i-j)/k for i,j,k in zip(img_x,means,sds)]\n",
    "jnk3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List comprehension and map were able to accomplish in one line what required six lines with\n",
    "# a for loop. What about speed advantages? You betcha!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit zscore_forloop(img_x,means,sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit list(map(lambda i,j,k: (i-j)/k,img_x,means,sds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit[(i-j)/k for i,j,k in zip(img_x,means,sds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alrighty, now lets try it on our neuroimage data and see how these different methods perform.\n",
    "# First, generate the data...\n",
    "\n",
    "x,y,z = dat.shape\n",
    "means = 2.5 * np.random.rand(x,y,z)\n",
    "sds = 1.5 * np.random.rand(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And now we test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit zscore_forloop(dat,means,sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit list(map(lambda i,j,k: (i-j)/k,dat,means,sds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit[(i-j)/k for i,j,k in zip(dat,means,sds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wow!! With more computation, the speed-up delivered by map and list comprehension is even\n",
    "# greater!! \n",
    "print('on my computer, list comprehension increased the speed by %s times, and map by %s times'%\n",
    "          (30000/129,30000/138))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just imagine, by using map, we can z-score over 200 images before the For loop z-scores one!\n",
    "# However, if you're going for performance, the best solution is to try to avoid iterating all\n",
    "# together and instead, vectorize. In other words, if you're working with matrices anyway,\n",
    "# just use math! This is how to obtain the optimal perforance in numpy. Have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit (dat-means)/sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Again, there are still some scenarios when iteration is necessary. Another trick to enhance\n",
    "# performance is the .flat attribute or np.arrays. This \"flattens\" an np.array, such that it\n",
    "# becomes 1-dimensional. So a 3x3 matrix for example would become a 9x1 array. However, the \n",
    "# result is not actually an array, but an \"iterator object\". This is sort of a one-time array\n",
    "# that is made for very rapid iteration, and which is not stored in memory. In other words,\n",
    "# once you iterate over it, its \"used up\" and you'll have to create a new iterator object to \n",
    "# use it again. Still, this method often provides a nice speed up. Have a look:\n",
    "\n",
    "def zscore_iter(mat,means,sds):\n",
    "    x,y,z = mat.shape # get the shape of the input matrix\n",
    "    newmat = np.empty((x*y*z)) # create an empty output matrix of the same dimensions \n",
    "    for i in range(len(newmat)):\n",
    "        newmat[i] = (mat.flat[i] - means.flat[i]) / sds.flat[i]\n",
    "\n",
    "    return newmat\n",
    "\n",
    "means = 2.5 * np.random.rand(4,4,4)\n",
    "sds = 1.5 * np.random.rand(4,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit zscore_forloop(img_x,means,sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit zscore_iter(img_x,means,sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only a slight speed-up, but a speed-up nonetheless. Using iterables into different\n",
    "# situations can often speed up your code, especially once you get the hang of using them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One last tool I'll show-off is one that can be found itertools. I recommend you browse the\n",
    "# itertools website, which has tons of very nice.. well.. iteration tools.\n",
    "\n",
    "# https://docs.python.org/2/library/itertools.html\n",
    "\n",
    "# Right now, I will show you \"combinatorial generators\". Much like \"zip\", these generators can\n",
    "# take multiple lists and generate every combination of them. This is very useful with neuro-\n",
    "# images because you often wish to iterate through indices on each axis of a multi-dimensional\n",
    "# array. These tools make this process fast, clean and easy\n",
    "\n",
    "import itertools\n",
    "x = np.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we'll use zip, which is a basic functionality of assembling the values at the same \n",
    "# index across the two lists into tuples. This is great for getting the indices of the diagonal\n",
    "# of a matrix\n",
    "list(zip(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's look at some of the combinatorial generators from itertools. Here, you can see\n",
    "# every possible combination between the two lists is generated. This is perfect for iteration\n",
    "# across multiple axes of differing dimensions\n",
    "list(itertools.product(x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perhaps you are working with a correlation matrix, where the values are exactly the same on\n",
    "# both sides of the diagonal. In this case, 3,e would be the same value as e,3. So if you want\n",
    "# to avoid these redundant axes, you could use combinations if you don't want the diagonal...\n",
    "list(itertools.combinations(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or use combinations_with_replacement to include the diagonal\n",
    "list(itertools.combinations_with_replacement(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, there are some situations where you might want every value except the diagonal, and\n",
    "# in this case you can utilize permutation. In this case, you get all values except 1,1 2,2 etc\n",
    "list(itertools.permutations(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How might this work in practice? Lets once again modify our"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Another useful tool for neuroimages is the masked array. Often, you will wish to ignore\n",
    "# certain parts of the iamge that do not contain data -- after all, the field of view is often \n",
    "# far larger than the brain itself. To do this, one can utilize \"masked\" arrays. These are nice \n",
    "# datatypes that store a copy of the data itself as well as information as to which items \n",
    "# should be masked out. So you dont lose any information or change the shape of your data, \n",
    "# but at the same time, you tell functions to ignore (i.e. not operate on) certain data points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets have a look at the docstring \n",
    "np.ma.masked_array?\n",
    "# I admit its a bit obtuse, but its important because it lets us see all of the arguments one \n",
    "# can pass. Basically, its telling us it accepts data and a mask. The mask is an array of\n",
    "# boolean values (could be True/False or 1/0) that is the same shape as the data. The masked\n",
    "# array will \"mask out\" (i.e. not operate on during computations) values in data for which\n",
    "# the value in the same index of the mask is True.\n",
    "\n",
    "# I'll demonstrate with a simple example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here is a small matrix\n",
    "ex_mat = np.arange(16).reshape(4,4)\n",
    "print(ex_mat,'\\n')\n",
    "\n",
    "# Now lets make a mask. Lets mask out all values <3 and >13\n",
    "ex_msk = (ex_mat>3) & (ex_mat<13)\n",
    "print(ex_msk,'\\n')\n",
    "\n",
    "# However, we read that a masked_array will mask out values that are True, not values that are\n",
    "# False. How can we invert our mask? Easy, by using the function np.logical_not\n",
    "ex_msk = np.logical_not(ex_msk)\n",
    "print(ex_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we're ready to create our masked array. All we need to do is enter our data and mask as\n",
    "# arguments\n",
    "ex_ma = np.ma.masked_array(ex_mat,ex_msk)\n",
    "ex_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Above, you can see the data we want masked is replaced by --, indicating this data will not\n",
    "# be used during computation. But don't worry, the data isn't lost, and you can always access\n",
    "# it like this\n",
    "ex_ma.data\n",
    "# Masked arrays are nice because they retain all of the functionality of an np.array, plus a\n",
    "# few other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So when would this be helpful in actual analyses?. Since we're using PET data and we're\n",
    "# looking at SUVR values, let's say we don't care about looking at values < 0.3, since such\n",
    "# values are likely outside the brain\n",
    "\n",
    "# Let's regenerate our data first\n",
    "dat = img.get_data()\n",
    "x,y,z = dat.shape\n",
    "\n",
    "# And now we'll make our mask\n",
    "dat_mask = np.logical_not(dat>0.3)\n",
    "\n",
    "# And finally we'll make our masked array\n",
    "mdat = np.ma.masked_array(dat,dat_mask)\n",
    "print(mdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Good! The masked_array has masked out values at the edges of the image -- thats what we\n",
    "# wanted! \n",
    "\n",
    "# But just to be sure there are some values there...\n",
    "mdat[75,75,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# However, somewhat counter-intuitively, using a masked_array will substantially slow\n",
    "# down your computations. You would think by *not* operating over certain values, you would\n",
    "# save time, but thats not the case\n",
    "means = 2.5 * np.random.rand(x,y,z)\n",
    "sds = 1.5 * np.random.rand(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit list(map(lambda i,j,k: (i-j)/k,mdat,means,sds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit[(i-j)/k for i,j,k in zip(mdat,means,sds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Still pretty fast but, on my computer, it was about a 7x slow-down. Still, masked_arrays can\n",
    "# be convenient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets do a few exercises to become more comfortable with these concepts. Afterwards, I'll\n",
    "# demonstrate some actual applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### EXECERCIZES PART B ####\n",
    "\n",
    "## Part A\n",
    "# Generate a 10 x 10 matrix of random numbers between 1000 and 10000. Then, find the square\n",
    "# root of each value. Do this using a For Loop, List Comprehension, Map, and vectors (matrix\n",
    "# math). Then, prove all matrices you've created are equal, and time each method to see which \n",
    "# is fastest \n",
    "\n",
    "# HINT: You will need to use separate cells to test the speeds\n",
    "# HINT: You can use np.allclose to check if the matrices are equal\n",
    "\n",
    "## Part B\n",
    "# Using a copy of our image data above, create a masked array that masks out all values below\n",
    "# 1. Then, multiply the masked matrix by 4, and print a slice of the new data to prove that\n",
    "# the computations only occured on unmasked values\n",
    "\n",
    "## Part C\n",
    "# Using our a copy of image data above, find the 3D index of the peak value at each slice along \n",
    "# the z-axis, and save it into a list. You can use whatever method you prefer, but make sure\n",
    "# to use itertools for the iteration over the axes.\n",
    "\n",
    "# HINT: np.argmax can help you here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ANSWERS BELOW\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### ANSWERS TO EXERCISES B #######\n",
    "\n",
    "## Part A\n",
    "# Generate a 10 x 10 matrix of random numbers between 1000 and 10000. \n",
    "ex_mtx = np.random.randint(1000,10000,(10,10))\n",
    "\n",
    "# Then, find the square root of each value. \n",
    "# For Loop \n",
    "def x_forloop(ex_mtx):\n",
    "    x,y = ex_mtx.shape\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            ex_mtx[i,j] = sqrt(ex_mtx[i,j])\n",
    "    \n",
    "    return ex_mtx\n",
    "\n",
    "# List Comprehension \n",
    "def x_lc(ex_mtx):\n",
    "    x,y = ex_mtx.shape\n",
    "    return np.array([sqrt(i) for i in ex_mtx.flat]).reshape(x,y)\n",
    "\n",
    "# Map\n",
    "def x_map(ex_mtx):\n",
    "    x,y = ex_mtx.shape\n",
    "    return np.array(list(map(lambda i: sqrt(i), ex_mtx.flat))).reshape(x,y)\n",
    "\n",
    "# Vectors (matrix math). \n",
    "def x_vec(ex_mtx):\n",
    "    return np.sqrt(ex_mtx)\n",
    "\n",
    "# prove all matrices you've created are equal\n",
    "x1 = x_forloop(ex_mtx)\n",
    "x2 = x_lc(ex_mtx)\n",
    "x3 = x_map(ex_mtx)\n",
    "x4 = x_vec(ex_mtx)\n",
    "\n",
    "#print(type(x1),type(x2),type(x3),type(x4))\n",
    "print('all the matrices equal?',np.allclose(x1,x2,x3,x4))\n",
    "\n",
    "# Then, time each to see which is fastest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit x_forloop(ex_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit x_lc(ex_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit x_map(ex_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit x_vec(ex_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Part B\n",
    "# Using a copy of our image data above, create a masked array that masks out all values below\n",
    "# 1. \n",
    "\n",
    "xdat = deepcopy(dat)\n",
    "msk = xdat>1\n",
    "x_ma = np.ma.masked_array(xdat,np.logical_not(msk))\n",
    "# Then, multiply the masked matrix by 4\n",
    "x_ma = x_ma * 4\n",
    "\n",
    "# and print a slice of the new data to prove that the computations only occured on \n",
    "# unmasked values\n",
    "x_ma.data[50,50,:] == xdat[50,50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Part C\n",
    "# Using our a copy of image data above, find the 3D index of the peak value at each slice along \n",
    "# the z-axis, and save it into a list\n",
    "xdat = deepcopy(dat)\n",
    "x,y,z = xdat.shape\n",
    "lc_idx = [[i,j,np.argmin(xdat[i,j,:])] for i,j in itertools.product(range(x),range(y))]\n",
    "lc_idx"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
