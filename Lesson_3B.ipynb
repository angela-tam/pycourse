{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########LESSON 3B: Data-wrangling Part 2 --> Spreadsheets ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Besides system files and neuroimages, you are guaranteed to encounter a lot of\n",
    "# spreadsheets when you're doing data-analysis. Often, you will be confronted with\n",
    "# scenarios involving making large-scale changes to spreadsheets, merging them, \n",
    "# filtering, and all sorts of other tasks that are hard or impossible to do my hand.\n",
    "\n",
    "# Scripting in Microsoft is awkward, and often, using existing spreadsheet GUIs or \n",
    "# software can be hard to control and ineffective. Luckily, spreadsheet wrangling \n",
    "# lends itself well to programming\n",
    "\n",
    "# While MatLab and R can handle spreadsheets, both of them are quite finicky and \n",
    "# unintuitive about it. One of Python's many advantages is it has a library called\n",
    "# Pandas that is specifically built for interacting with spreadsheets in a \n",
    "# (relatively) user-friendly way! \n",
    "\n",
    "# This lesson will be all about using Pandas to interact with spreadsheets. In the\n",
    "# end, we will use what we learned to prepare our data for the next lesson: \n",
    "# Data Analysis!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, lets import pandas and a few other modules\n",
    "import pandas\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets read in the results from our PyCourse survey and create a Pandas Dataframe out\n",
    "# of it. The spreadsheet is in .csv format. Loading a csv in Pandas is very easy:\n",
    "\n",
    "# identify path to csv\n",
    "sheet = os.path.join(os.getcwd(),'stuff/pycourse_survey.csv')\n",
    "\n",
    "# load csv into a pandas dataframe\n",
    "df = pandas.read_csv(sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now, by printing df, we can see our spreadsheet!\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# However, this is a bit hard to view in this format. Luckily, if we simply type\n",
    "# the name of our dataframe, and there is no other output generated within the cell\n",
    "# we get a much nicer and more readable display of the spreadsheet. See:\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Also, if you just want to see the beginning of your DataFrame, you can do this:\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Which takes up less space. You can see the end with df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Before I get into all the cool things we can do with out dataframe, I want to show you\n",
    "# a few more points about loading Dataframes, and a few features of Dataframe objects\n",
    "\n",
    "# First, this .csv import went very well -- the first row ended up as our Dataframe header as \n",
    "# we wanted. However, sometimes the import doesn't go that well. Luckily, there are a few\n",
    "# simple arguments that you can pass that can fix the problem. See the read_csv docstring\n",
    "# to find out\n",
    "\n",
    "pandas.read_csv?\n",
    "\n",
    "# I'll describe some of the useful arguments here:\n",
    "\n",
    "# Sep: if your .csv is not comma-separated at all, but delimited by some other character, you\n",
    "# can set that here. For example, it it was delimited by a ;, you would just type \n",
    "# read_csv(sheet,sep=';')\n",
    "\n",
    "# delim_whitespace: if set to True, the Dataframe will also uses whitespace (' ') as a sep.\n",
    "\n",
    "# header: if you have no header (no column names), you can pass header=None. If you're column\n",
    "# names are on a different row than the first, you can type header = x, where x is an int\n",
    "# referring to the row # of your header. If you have a multi-index (more than one level of\n",
    "# column names), you can pass a list of ints indicating which rows your different headers\n",
    "# are\n",
    "\n",
    "# usecols: if you only want to use some of the columns, but not all, you can pass a list of\n",
    "# ints or strs indicating the column numbers or names you want to use\n",
    "\n",
    "# As you can see, there are many others, but these are the ones you might use a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One of the great things about pandas that sets it above Matlab and R is how easily\n",
    "# it can load other filetypes into Dataframes -- even Excel files!! \n",
    "\n",
    "# To demonstrate, I will save our csv as an excel file, then load that excel file with\n",
    "# pandas\n",
    "\n",
    "new_fl = os.path.join(os.getcwd(),'stuff/excel_file.xls') # its important that I pass .xls or .xlsx here\n",
    "df.to_excel(new_fl)\n",
    "\n",
    "# we now have an excel file which can be opened easily in excel\n",
    "os.path.isfile(new_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Excel files are just as easy to load with pandas. The only extra step is we have to\n",
    "# tell pandas what \"sheet\" we want to load. Excel files can have multiple sheets and \n",
    "# ExcelFile only loads one at a time. If you're not sure what the names are of the \n",
    "# sheets, you can use pandas to find out\n",
    "\n",
    "x_df = pandas.ExcelFile(new_fl)\n",
    "x_df.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Great. So our sheet is called 'Sheet1'. Now lets access that sheet:\n",
    "\n",
    "xdf = x_df.parse('Sheet1')\n",
    "xdf.head()\n",
    "\n",
    "# If you know your sheet ahead of time, you could always just type this:\n",
    "# xdf = pandas.ExcelFile(new_fl).parse('Sheet1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pandas can load Dataframes from many other formats as well:\n",
    "\n",
    "#pandas.read_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Okay, now that we have our Dataframe, lets look at some simple functions and methods\n",
    "# associated with it\n",
    "\n",
    "# to see the number of rows\n",
    "print('this spreadsheet has %s rows'%len(df))\n",
    "\n",
    "# or the number of rows and columns\n",
    "print('rows x columns = ',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There's also a nifty function that will tell you basic statistics about every column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also get individual statistics if you like:\n",
    "\n",
    "df.mean()\n",
    "\n",
    "# Note that these are the only columns returned because these are the only columns with\n",
    "# all numbers in them. We'll fix that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataframes have methods (functions, as you've seen above), but they also have\n",
    "# attributes that can be accessed. Two of the most important are the columns and\n",
    "# the index. Luckily, these are very intutive.\n",
    "\n",
    "print('the index of df is ',df.index)\n",
    "print('\\n')\n",
    "print('the columns of df are ',df.columns)\n",
    "print('\\n')\n",
    "\n",
    "# Notice how I do not give these (parentheses) because they are not functions, they\n",
    "# are attributes. Actually, they behave a lot like lists! As such, you can index and \n",
    "# slice them:\n",
    "print('the index of the 14th row is ',df.index[14])\n",
    "print('\\n')\n",
    "print('the 15th through 19th columns are ',df.columns[15:19])\n",
    "\n",
    "# As we'll see later, you can also directly modify these attributes in the same way you would\n",
    "# modify a list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Indexing, Slicing and Querying ######\n",
    "\n",
    "# There are *many* ways to to index and slice. It can get a bit confusing because\n",
    "# there is a lot of redundancy and a lot of slight differences between methods.\n",
    "\n",
    "# You can easily print all values in a column. These three approaches all have the\n",
    "# same output\n",
    "df['What do you think of beards?']\n",
    "\n",
    "df[df.columns[-2]]\n",
    "\n",
    "df.ix[:,'What do you think of beards?'] # or df.ix[:,df.columns[-2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is very similar to slicing. These \"slices\" (they're actually called Series in\n",
    "# pandas) can be saved into their own variables\n",
    "\n",
    "ser = df.ix[:,df.columns[-2]]\n",
    "print(ser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These series have their own set of functions. See below:\n",
    "print(ser.unique())\n",
    "print('\\n')\n",
    "print(ser.describe())\n",
    "print('\\n')\n",
    "print(ser.hasnans)\n",
    "print('\\n')\n",
    "print(ser.value_counts())\n",
    "print('\\n')\n",
    "\n",
    "# Actually, they have almost every function of a full dataframe!\n",
    "\n",
    "# They can also be easily converted to lists\n",
    "print(ser.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By the way, you can use the above methods to print multiple Series at once by putting\n",
    "# your column labels inside of a list!\n",
    "\n",
    "# I'll do it below, but I'll just print the beginning in order to save space\n",
    "\n",
    "df[[df.columns[-2],df.columns[35]]].head()\n",
    "\n",
    "# Be aware of all these different [square brackets] and how each set is doing something\n",
    "# different in the line above. The outer set is used to index df, the middle set is used\n",
    "# to indicate a list is being formed, and the inner sets are used to index df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Slicing rows (rather than columns) is just as simple and also include redundant functionality\n",
    "# I will use two redundant commands to print every value for the 10th row\n",
    "\n",
    "# Again, I used head() to save space\n",
    "\n",
    "df.iloc[10]\n",
    "df.ix[10].head()\n",
    "\n",
    "# Just like with slicing columns, a slice taken along the index (a row) is also a pandas Series\n",
    "# and also retains all the functions and methods of a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Like above, you can pass slices from the index, \n",
    "df.ix[8:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are also ways to get exact data points from within your Dataframe. As with\n",
    "# indexing and slicing, there are several ways to go about this. I prefer the .ix\n",
    "# attribute. You need only to pass it the number (or name) of the row and the name\n",
    "# (or number) of the column\n",
    "\n",
    "# As such, these both do the same thing, which is print the value in the 4th row\n",
    "# at the 12th column.\n",
    "\n",
    "df.ix[5,'How spicy do you like your food?']\n",
    "df.ix[5,12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In much the same fashion, you can select exact slices that you want to pull out of\n",
    "# the data. Here, I will print the values in the 12th-14th columns for the 2nd-4th \n",
    "# rows.\n",
    "\n",
    "df.ix[2:4,12:14]\n",
    "\n",
    "# And just like the other attributes I've shown you, such slices are actually pandas\n",
    "# Series and therefore come with all of the functions of a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why don't you try a few! (Feel free to do them each in different cells if you prefer\n",
    "# the output that way)\n",
    "\n",
    "# print all values for the column What time is it right now?\n",
    "\n",
    "# print all values in the 10th, 19th, and 28th columns\n",
    "\n",
    "# print all values for row 9-16\n",
    "\n",
    "# print the value for row 49 for the column: \n",
    "# 'How many romantic relationships have you been in that have lasted at least 6 months'\n",
    "\n",
    "# print the values for row 24-28 and columns 30-35\n",
    "\n",
    "# Use a For loop to determine which columns have NaNs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### These are not real exercises but I'll put the answers below...\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "df['What time is it right now?']\n",
    "df[[df.columns[10],df.columns[19],df.columns[28]]]\n",
    "df.ix[9:16]\n",
    "df.ix[49,'How many romantic relationships have you been in that have lasted at least 6 months']\n",
    "df.ix[24:28,30:35]\n",
    "for i in range(len(df.columns)):\n",
    "    if df.ix[:,i].hasnans:\n",
    "        print(df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now that you know a thing or two about extracting slices from your Dataframe, I'll show\n",
    "# you how to \"query\"\n",
    "\n",
    "# When you pass simple Truth statements to a pandas Series, it does not give you a single\n",
    "# Boolean response, but rather a response for each value in the Series\n",
    "\n",
    "homebodies = df['How many continents have you visited']\n",
    "homebodies < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can use the & sign to include additional arguments in your query\n",
    "\n",
    "driving = df['How good do you think you are a driving (3 is average)']\n",
    "sports = df['How good are you at sports?']\n",
    "overconfident = (sports > 4) & (driving > 4)\n",
    "overconfident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also slice a dataframe using a query. Here I'll return all dataframe entries\n",
    "# that fit the query for overcondence\n",
    "df[overconfident]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also use a \"dysjunction\" query, which is similar to saying \"and not\"\n",
    "# So, here, I'll ask if there is anyone that reported \"Yes\" to Can you roll your\n",
    "# tongue, but did not report \"No\" to Do you have any food allergies.\n",
    "\n",
    "# So, in other words, this will capture everyone who can either can roll their tongue \n",
    "# or has food allergies, but not both.\n",
    "\n",
    "(df['Can you roll your tongue?'] == 'Yes') | (df['Do you have any food allergies or intolerances?'] == 'No') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What!?!? True for everyone? Does that mean that no one who can roll their tongue \n",
    "# also has food allergies or intolerances?? Let's check that!\n",
    "(df['Can you roll your tongue?'] == 'No') & (df['Do you have any food allergies or intolerances?'] == 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unbelievable! Maybe we're onto something here? Maybe rolling your tongue makes you\n",
    "# vulnerable to food allergies. Maybe your food allergies weaken the integrity of your\n",
    "# tongue, allowing you to roll it. Who knows? \n",
    "\n",
    "# By the way, I didn't find that by chance. I used Python to search every possible \n",
    "# two-statement dysjunction query to find one that was True for everyone. This\n",
    "# was the only statement that came up.\n",
    "\n",
    "# The code I wrote is below. I don't recommend you run it in class because it might take \n",
    "# a long time to run on your computer. But you can have a look at how the code that allowed\n",
    "# me to do this works, and get a sense of why Python can drastically expand the things\n",
    "# you can do with your spreadsheet.\n",
    "\n",
    "# The code actually evaluated 50,536 statements in a couple of minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(8,len(df.columns)): # for every column (except the first 8) <- for the left side of the statement\n",
    "    print(df.columns[i]) # keep track of status by printing which column you're on\n",
    "    col = df.columns[i]\n",
    "    uni = df[col].unique() # get a list of the unique value in that column\n",
    "    if len(uni) > 10: \n",
    "        continue # if there are more than 10 unique values, skip this column\n",
    "    for u in uni: # for each unique value in the column\n",
    "        for j in range(8,len(df.columns)): # now we have to do the same thing for the right side of the statement\n",
    "            if i == j or j < i:\n",
    "                continue # skip same column or the inverse of statements already searched\n",
    "            col2 = df.columns[j]\n",
    "            uni2 = df[col2].unique()\n",
    "            if len(uni) > 10:\n",
    "                continue\n",
    "            for u2 in uni2:\n",
    "                stmnt = (df[col] == u) | (df[col2] == u2) # make dysjunction statement\n",
    "                count = count+1\n",
    "                if all(stmnt == True): # Assess if statement is true for every row\n",
    "                    print('>>>>>>>>>>>>',col,u,col2,u2,'<<<<<<<<<<<') # if so, print information about the statement\n",
    "\n",
    "print('%s statements evaluated'%count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There is more you can do with querying, but for now, I'll teach you one last trick\n",
    "# You can have query based on whether a certain response is within a list of values\n",
    "# Here's how it works\n",
    "\n",
    "primary_colors = ['red','blue','yellow']\n",
    "df[\"What color is the shirt/dress/upper-body-clothing you're wearing right now, if any?\"].isin(primary_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'll leave some space here for you to experiment with your own queries. Dont forget\n",
    "# though that (for now) only a few columns have *only numbers*, and so only a few\n",
    "# columns will respond to < and > arguments\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### MODIFYING DATAFRAMES #######\n",
    "\n",
    "# Before I show you how to modify DataFrames, it would first be good to learn how to\n",
    "# \"save\" them, as its always good to save before modifying. \n",
    "\n",
    "# The most traditional way of \"saving\" a DataFrame is to write it to a file, either\n",
    "# a new file (like Save as...) or an existing file (like Save)\n",
    "\n",
    "# This is very easy with Python. You can save to a number of different formats:\n",
    "# df.to_\n",
    "\n",
    "# Let's overwrite the file we already have:\n",
    "print(sheet)\n",
    "df.to_csv(sheet) # that's it. Its saved!\n",
    "\n",
    "# You can also edit the characteristics of the saved file -- see the docstring for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you don't want to write to file and instead want to maintain a copy of the \n",
    "# DataFrame within your Python session, you can do that too. BUT!!! Please be \n",
    "# aware: DataFrames are MUTABLE OBJECTS, like lists!  \n",
    "\n",
    "# That means that, even if you make a copy of a DataFrame, if you modify the copy,\n",
    "# the original will change as well!!!\n",
    "\n",
    "newdf = df\n",
    "print('here is the value at row 1, column 1 for df and newdf before modifying newdf')\n",
    "print(df.ix[1,1])\n",
    "print(newdf.ix[1,1])\n",
    "print('\\n')\n",
    "\n",
    "newdf.ix[1,1] = 'changed!!'\n",
    "print('here is the value at row 1, column 1 for df and newdf after modifying newdf')\n",
    "print(df.ix[1,1])\n",
    "print(newdf.ix[1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's reload our old unchanged csv now to get rid of the changes\n",
    "df = pandas.read_csv(sheet)\n",
    "\n",
    "# One way around this issue is to make a \"deepcopy\", which will make an immutable instance\n",
    "# of whatever it is you want to copy.\n",
    "\n",
    "from copy import deepcopy\n",
    "newdf = deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we'll do the same thing as we did two cells up:\n",
    "print('here is the value at row 1, column 1 for df and newdf before modifying newdf')\n",
    "print(df.ix[1,1])\n",
    "print(newdf.ix[1,1])\n",
    "print('\\n')\n",
    "\n",
    "newdf.ix[1,1] = 'changed!!'\n",
    "print('here is the value at row 1, column 1 for df and newdf after modifying newdf')\n",
    "print(df.ix[1,1])\n",
    "print(newdf.ix[1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modifying DataFrames is fairly straightforward. As you can see, we can modify \n",
    "# DataFrame values by just setting them:\n",
    "\n",
    "print(newdf.ix[10,10])\n",
    "newdf.ix[10,10] = 'Sorry, just English'\n",
    "print(newdf.ix[10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modifying the index, column or a slice is a bit trickier, as the \"replacement\"\n",
    "# variable must \"fit\" into the dimensions of the DataFrame\n",
    "\n",
    "# For example, if we try to set df.inde to a list of values that are less than\n",
    "# len(df.columns), we'll get an error\n",
    "\n",
    "newdf.index = ['list','of','indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# However, if we wanted to replace our index with something of the right length, for \n",
    "# example another column, we would have no trouble! Let's replace the index with the\n",
    "# user's \"codename\", which is listed in the column called 'Enter your codename here'\n",
    "newdf.index = newdf['Enter your codename here']\n",
    "\n",
    "# Now have a look at our DataFrame!\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modifying entire rows and columns works in the same way. Let's say you wanted to update\n",
    "# a subject's information (i.e. change an entire row). As long as your input dimensions\n",
    "# match the dimensions of the row, it will work fine:\n",
    "\n",
    "new_info = range(len(newdf.columns)) # creating a range the same length as the # of columns\n",
    "newdf.ix[5] = new_info # replacing the 5th row with this range of consecutive numbers\n",
    "newdf.ix[5].head() # show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding new rows and columns is also pretty easy. Have a look:\n",
    "\n",
    "new_col = range(len(df.index))\n",
    "newdf.ix[:,'new_columns'] = new_col\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using this method, its easy to make a new column out of an old column\n",
    "\n",
    "# make the new columns\n",
    "col = df['What are the chances (in percentage from 1-100) that the Dutch National team will win a EuroCup or WorldCup championship in the next 10 years?']\n",
    "new_col = []\n",
    "for row in col:\n",
    "    try:\n",
    "        val = float(row)\n",
    "    except:\n",
    "        try:\n",
    "            val = float(row[:-1])\n",
    "        except:\n",
    "            val = None\n",
    "    if val:\n",
    "        if val>50:\n",
    "            new_col.append('optimist')\n",
    "        else:\n",
    "            new_col.append('pessimist')\n",
    "    else:\n",
    "        new_col.append(np.nan)\n",
    "\n",
    "# add it to the DataFrame\n",
    "newdf.ix[:,'Life Outlook'] = new_col\n",
    "\n",
    "# show\n",
    "newdf.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can add new rows (in this case, subjects) using the same approach. \n",
    "# Since our index is Codename, we can just add a few new codename. We'll\n",
    "# leave the rows empty for now\n",
    "\n",
    "new_codenames = ['twist_the_dutchie','bitterballer','Feyenoord_sux']\n",
    "for cn in new_codenames:\n",
    "    newdf.ix[cn] = np.full(len(newdf.columns),np.nan)\n",
    "    \n",
    "newdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping rows and columns is also very straightforward. You can use the .drop method.\n",
    "newdf.drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If I want to drop one of the new rows, I can do so easily with .drop.\n",
    "\n",
    "# This will show me what the modified DataFrame will look like without doing the modification.\n",
    "\n",
    "newdf.drop('twist_the_dutchie',axis=0).tail()\n",
    "\n",
    "# Note that I set axis to 0 -- that means I want to delete a row, not a column\n",
    "# Also note that newdf.drop(df.index[-3],axis=0) would do the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# However, notice that this did not actually perform the modification\n",
    "newdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To actually perform the operation, we must set the inplace argument to True:\n",
    "newdf.drop('twist_the_dutchie',axis=0,inplace=True)\n",
    "newdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can also use .drop to remove columns. You just need to enter a column name and make sure\n",
    "# axis is set to 1 instead of 0:\n",
    "\n",
    "print(newdf.columns[-2])\n",
    "newdf.drop(newdf.columns[-2],axis=1,inplace=True)\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Another useful tool for dropping is .dropna, which will get rid of entire rows and\n",
    "# columns if they have any NaNs, or if they are all NaNs, depending on the input.\n",
    "\n",
    "# Here, I will get rid of subjects that have all NaNs\n",
    "# If I only wanted to visualiz what would happen before actually removing the columns,\n",
    "# I would set inplace to False (the default)\n",
    "newdf.dropna(axis=0, how='all',inplace=True)\n",
    "newdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# similarly, I will use .dropna to find out how many subjects and columns would be left\n",
    "# if I dropped subjects and columns with any NaNs\n",
    "\n",
    "subjs_left = len(newdf.dropna(axis=0,how='any'))\n",
    "cols_left = len(newdf.dropna(axis=1,how='any').columns)\n",
    "\n",
    "print('there would be %s subject left, and %s columns left,'%(subjs_left,cols_left), \n",
    "      'if I dropped those with NaNs in them...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Iterating DataFrames ####\n",
    "\n",
    "# Based on what you've already learned this lesson, you can already iterate through\n",
    "# dataframes with the tools you know.\n",
    "\n",
    "# For example, you can build For loops based off of the index or the columns\n",
    "\n",
    "spiciness = {1: \"not at all\",2:\"not very\",3:\"somewhat\",4:\"pretty\",5:\"extremely\"}\n",
    "\n",
    "for sub in df.index:\n",
    "    spice = df.ix[sub,'How spicy do you like your food?']\n",
    "    if spice in spiciness.keys():\n",
    "        print('subject %s likes their food %s spicy'%(sub,spiciness[spice]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# However, there are some situations where using a built-in iterator is preferable.\n",
    "# DataFrame objects have a few built in iterators.\n",
    "# newdf.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One that I sometimes find useful is iterrows(). This will iterate through each row,\n",
    "# obviously. You should pass two different iterator variables to the For loop -- the \n",
    "# first will represent the row index, and the second will represent the entire row.\n",
    "\n",
    "# There for, row[0] would be the value in the first column for that row. Have a look:\n",
    "\n",
    "for ind,row in df.iterrows():\n",
    "    print(ind,row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Dealing with multi-index ####\n",
    "\n",
    "# For example, consider the following situation. Here, I will build a little DataFrame \n",
    "# from scratch:\n",
    "\n",
    "subs = [1,1,1,1,1,2,3,3,4,4,4,5,5]\n",
    "visit = [1,2,3,4,5,1,1,2,1,2,3,1,2]\n",
    "cog = [(x+np.random.randint(1,5)) for x in subs]\n",
    "longi_df = pandas.DataFrame(index=subs,columns=['visit','DS_backwards'])\n",
    "longi_df['visit'] = visit\n",
    "longi_df['DS_backwards'] = cog\n",
    "\n",
    "longi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Because my index is subject, look what happens if I try to index by subject:\n",
    "\n",
    "longi_df.ix[1]\n",
    "\n",
    "# I get a series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One way to deal with this is to use a multi-index\n",
    "tups = []\n",
    "for i in range(len(subs)):\n",
    "    tups.append((subs[i],visit[i]))\n",
    "m_index = pandas.MultiIndex.from_tuples(tups)\n",
    "nlongi_df = pandas.DataFrame(index=m_index,columns=['DS_backwards'])\n",
    "nlongi_df['DS_backwards'] = cog\n",
    "nlongi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now lets have a look at the indexing:\n",
    "\n",
    "# This will return the same thing as before:\n",
    "nlongi_df.ix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# But we can also index using the multi-index:\n",
    "nlongi_df.ix[1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And to be more specific:\n",
    "nlongi_df.ix[1,3]['DS_backwards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There is SOOOOO much more you can do with pandas that I will not get into for right now.\n",
    "# But the pandas website is a great resource. Check out for example these pages:\n",
    "\n",
    "# Cookbook: http://pandas.pydata.org/pandas-docs/stable/cookbook.html\n",
    "# Tutorials: http://pandas.pydata.org/pandas-docs/stable/tutorials.html\n",
    "# Useful statistics: http://pandas.pydata.org/pandas-docs/stable/computation.html\n",
    "# Merging spreadsheets: http://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "# And so much more, for both beginners and experts!\n",
    "\n",
    "# However, there is one more thing I want to demonstrate because I use it all the time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NaNs can be really hard to deal with. Consider this\n",
    "a=np.nan\n",
    "b=np.nan\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print('Does a = b?')\n",
    "print(a == b)\n",
    "print('\\n')\n",
    "\n",
    "print('does a = NaN???')\n",
    "print(a == np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So, for example, if you wanted to iterate through a DataFrame or a Series and get\n",
    "# rid of NaNs, how would you do it? You couldn't just say if value == np.nan.\n",
    "\n",
    "# One function that has helped me is pandas.notnull. Observe:\n",
    "\n",
    "print('is a not null?',pandas.notnull(a))\n",
    "# which means\n",
    "print('is a null?',not pandas.notnull(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic Pandas exercises\n",
    "\n",
    "## PART A\n",
    "# The following column has string values representing numbers inside of it:\n",
    "# df['Pick another number from 1 to 100']\n",
    "# Change these values to floats, and find the mean of the new columns \n",
    "\n",
    "# Next, the column df['Exactly how far in km is your commute to work?'] also has numbers that\n",
    "# are represented as string. Do the same thing with this column. (It will be trickier!)\n",
    "\n",
    "## Part B\n",
    "# Create a new dataframe, x, using only the last 10 columns of df\n",
    "# Then, create a new dataframe, y, using only the following columns:\n",
    "# df['Enter your codename here'] , df['Timestamp'] , \n",
    "# df[Were you born in the Netherlands?'], df['What do you think of beards?']\n",
    "\n",
    "## Part C\n",
    "# Create a new DataFrame of only rows corresponding to people 1) born in the Netherlands,\n",
    "# and 2) that remember their dreams\n",
    "\n",
    "## Part D\n",
    "# Make a deepcopy of df. Then, for all columns that have <50 valid values (i.e. not NaNs),\n",
    "# remove the column from the DataFrame.\n",
    "\n",
    "## Part E\n",
    "# JUST NEED TO DO A FEW THINGS HERE.....\n",
    "nlongi_df['Months since baseline'] = np.empty((len(nlongi_df.index),1))\n",
    "for i,j in nlongi_df.index:\n",
    "    if j == 1:\n",
    "        nlongi_df.ix[(i,j),'Months since baseline'] = 0\n",
    "    else:\n",
    "        adder = nlongi_df.ix[(i,j-1),'Months since baseline'] + np.random.randint(6,18)\n",
    "        nlongi_df.ix[(i,j),'Months since baseline'] = adder\n",
    "# Okay, so now nlongi_df has a column explaining how much time has passed since baseline, in\n",
    "# months. Make a new DataFrame with two columns: subject (i.e. 1-5), and improvement. The \n",
    "# value in improvement should be the raw change in DS_backwards between the subject's first\n",
    "# and last session, divided by the number of months that had passed, and multiplied by 12.\n",
    "# So: ((cog_fu - cog_bl) / months between cog_fu & cog_bl) * 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########## ANSWERS TO EXERCISES #################\n",
    "## PART A\n",
    "# The following column has string values representing numbers inside of it:\n",
    "# df['Pick another number from 1 to 100']\n",
    "# Change these values to floats, and find the mean of the new columns \n",
    "\n",
    "col = df['Pick another number from 1 to 100']\n",
    "ncol = pandas.to_numeric(col,errors='coerce')\n",
    "print(ncol.head())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Next, the column df['Exactly how far in km is your commute to work?'] also has numbers that\n",
    "# are represented as string. Do the same thing with this column. (It will be trickier!)\n",
    "\n",
    "col = df['Exactly how far in km is your commute to work?'] \n",
    "ncol = []\n",
    "for val in col:\n",
    "    try:\n",
    "        val = float(val)\n",
    "        ncol.append(val)\n",
    "    except:\n",
    "        if 'k' in val:\n",
    "            val = val.split('k')[0]\n",
    "        if ',' in val:\n",
    "            val = val.replace(',','.')\n",
    "        try:\n",
    "            val = float(val)\n",
    "            ncol.append(val)\n",
    "        except:\n",
    "            print('could not coerce %s to float, making a NaN'%(val))\n",
    "            ncol.append(np.nan)\n",
    "\n",
    "ncol = pandas.Series(ncol)            \n",
    "print(ncol.head())\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "## Part B\n",
    "# Create a new dataframe, x, using only the last 10 columns of df\n",
    "# Then, create a new dataframe, y, using only the following columns:\n",
    "# df['Enter your codename here'] , df['Timestamp'] , \n",
    "# df[Were you born in the Netherlands?'], df['What do you think of beards?']\n",
    "x = df[df.columns[-10:]]\n",
    "cols = ['Enter your codename here', 'Timestamp' , 'Were you born in the Netherlands?', 'What do you think of beards?']\n",
    "y = df[cols]\n",
    "print(x.head(),'\\n')\n",
    "print(y.head(),'\\n')\n",
    "\n",
    "## Part C\n",
    "# Create a new DataFrame of only rows corresponding to people 1) born in the Netherlands,\n",
    "# and 2) that remember their dreams\n",
    "\n",
    "stmnt =  (df['Were you born in the Netherlands?'] =='Yes') & (df['Do you usually remember your dreams?']=='Yes')\n",
    "newdf = df[stmnt]\n",
    "newdf\n",
    "\n",
    "## Part D\n",
    "# Make a deepcopy of df. Then, for all columns that have <50 valid values (i.e. not NaNs),\n",
    "# remove the column from the DataFrame.\n",
    "\n",
    "ndf = deepcopy(df)\n",
    "print('ndf started with %s columns \\n'%(len(ndf.columns)))\n",
    "\n",
    "for col in ndf.columns:\n",
    "    cont = []\n",
    "    for val in ndf[col]:\n",
    "        if pandas.notnull(val):\n",
    "            cont.append(1)\n",
    "    if len(cont) < 50:\n",
    "        print('%s only has %s valid values, dropping...'%(col,len(cont)))\n",
    "        ndf.drop(col,axis=1,inplace=True)\n",
    "print('\\nnow ndf has %s columns \\n'%(len(ndf.columns)))\n",
    "\n",
    "## Part E\n",
    "# JUST NEED TO DO A FEW THINGS HERE.....\n",
    "nlongi_df['Months since baseline'] = np.empty((len(nlongi_df.index),1))\n",
    "for i,j in nlongi_df.index:\n",
    "    if j == 1:\n",
    "        nlongi_df.ix[(i,j),'Months since baseline'] = 0\n",
    "    else:\n",
    "        adder = nlongi_df.ix[(i,j-1),'Months since baseline'] + np.random.randint(6,18)\n",
    "        nlongi_df.ix[(i,j),'Months since baseline'] = adder\n",
    "# Okay, so now nlongi_df has a column explaining how much time has passed since baseline, in\n",
    "# months. Make a new DataFrame with two columns: subject (i.e. 1-5), and improvement. The \n",
    "# value in improvement should be the raw change in DS_backwards between the subject's first\n",
    "# and last session, divided by the number of months that had passed, and multiplied by 12.\n",
    "# So: ((cog_fu - cog_bl) / months between cog_fu & cog_bl) * 12\n",
    "# If a subject has only one visit, just enter a NaN\n",
    "\n",
    "jnk = []\n",
    "for i,j in nlongi_df.index:\n",
    "    jnk.append(i)\n",
    "subs = list(set(jnk))\n",
    "newdf = pandas.DataFrame(index=subs,columns=['improvement'])\n",
    "for sub in subs:\n",
    "    cogs = list(nlongi_df.ix[sub]['DS_backwards'])\n",
    "    mons = list(nlongi_df.ix[sub]['Months since baseline'])\n",
    "    if len(mons) > 1:\n",
    "        cog_bl = cogs[0]\n",
    "        cog_fu = cogs[1]\n",
    "        fu_time = mons[-1]\n",
    "        improv = ((cog_fu - cog_bl) / fu_time) * 12\n",
    "        newdf.ix[sub,'improvement'] = improv\n",
    "    else:\n",
    "        newdf.ix[sub,'improvement'] = np.nan\n",
    "        \n",
    "newdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############# Practical Exercises ############# \n",
    "# We're going to do things a bit differently this time. These exercises will\n",
    "# actually be composed of different things we need to do to \"process\" our data for \n",
    "# the next Lesson: Data Analysis. Many of the columns have issues in them that will make \n",
    "# make them difficult to use in analyses. The following exercises will help us get rid\n",
    "# of those issues and create new column that we can use to analyze. We will end up \n",
    "# using these functions to quickly and painlessly create data-columns in the next\n",
    "# Lesson\n",
    "\n",
    "# Don't worry, we will have other pandas-related exercises in the future that will\n",
    "# for example deal with longitudinal data wrangling and spreadsheet management.\n",
    "\n",
    "\n",
    "# All of these exercises will involve creating functions to change the values in\n",
    "# different columns. Each function will take a column as input, and return a \n",
    "# pandas Series (really, just a column) as output. \n",
    "\n",
    "# I recommend completing the exercises in separate cells for the purposes of organization\n",
    "# The exercises are at many different (difficulties). See how far you can get, but don't \n",
    "# quit because you can't do one. Try another, or walk away and come back later :-)\n",
    "# The exercises are not in order based on difficulty, so keep scrolling down. Don't forget\n",
    "# to try googling before you give up!\n",
    "\n",
    "# <<<<HINT!>>>> Remember that DataFrames are mutable, and so are Series. If you are planning\n",
    "# on modifying your input columns directly, those input columns may change in the original\n",
    "# DataFrame! Make sure to either make deepcopies of your input colums, or build your series'\n",
    "# from scratch.\n",
    "\n",
    "\n",
    "\n",
    "## Part A -- Harmonize case  (Straightforward)\n",
    "# Many columns recieve string input. However, some users have chosen to use capital letters\n",
    "# while others have not. \n",
    "# See for example df[\"What color is the shirt/dress/upper-body-clothing you're wearing right now, if any?\"].unique()\n",
    "# Create a function that will make all string responses in a given column lowercase\n",
    "\n",
    "\n",
    "## Part B -- Character count   (Straightforward)\n",
    "# For the column 'Fill this text box with gibberish by mashing random keyboard keys', users \n",
    "# have entered a random number of string characters. We can count the number of characters\n",
    "# the users typed and use it as a measure of \"aggression\" or \"inner-stress\". Write a function\n",
    "# that will count the number of characters for each value in a columns\n",
    "\n",
    "\n",
    "## Part C -- Handle NaNs    (Just a bit bumpy)\n",
    "# Many columns have NaNs, and depending on what program you use to analyze data, you may need\n",
    "# do address them. Write a function that handles the NaNs in a column. There should be an \n",
    "# argument where the user can define what they wish to do with the NaNs. They can either\n",
    "# remove all rows with a NaN from the column, or they can code the NaNs as something else.\n",
    "# You will obviously need a third argument where the user inputs what they want to code the\n",
    "# NaN as (example input could be 999 or np.nan or 'missing')\n",
    "\n",
    "\n",
    "## Part D -- Encode    (Just a bit bumpy)\n",
    "# Write a function that will take a dictionary as input. The dictionary should have column\n",
    "# values as keys and new (encoded) values as the corresponding dictionary values. For example,\n",
    "# input could be {Yes: 1, No: 0}. The function should apply the code to the column.\n",
    "# If the dictionary argument is set to None, the function should automatically encode unique\n",
    "# values with sequential integers.\n",
    "\n",
    "\n",
    "## Part E -- Binary encode      (Tricky)\n",
    "# Many columns have users choose from several different choices. See for example:\n",
    "# df['If you had to choose one, what would be your favorite type of beer?'].unique()\n",
    "# Create a function that will set one of those values to 1, and the rest to 0. The\n",
    "# value to be set as 1 should be specified by the user. I could use this for example\n",
    "# if I wanted to have a new variable called \"IPA Drinkers\".\n",
    "\n",
    "# The user can also input a list, in which case all values within the list are changed\n",
    "# to 1, and everything else to 0. The function should call a specific error if the\n",
    "# user inputs a value that is not an existing value in the column. \n",
    "\n",
    "# BONUS: Add extra feature to allow the user to choose whether or not to leave NaNs as NaNs\n",
    "\n",
    "\n",
    "## Part F -- Purify int/floats        (Tricky)\n",
    "# Many columns have examples where users have input string when they were suppose to input \n",
    "# an integer or float. See for example: \n",
    "# df[\"How many romantic relationships have you been in that have lasted at least 6 months\"].unique()\n",
    "# Write a function that handles string inputs when they are supposed to be floats or ints. The function\n",
    "# should have two modes, evaluate and apply. If evaluate, the function will return all values (as well\n",
    "# as their index) that are not floats. This will let you evaluate whether you can fix these values\n",
    "# (either manually or with your encode function). If apply, the function will remove all non int/float\n",
    "# values and replace them with NaNs.\n",
    "\n",
    "# If mode is set to apply, the function should return the modified column. If mode is set to evaluate,\n",
    "# the function should return the indices of the non-float/int values\n",
    "\n",
    "\n",
    "## Part G -- Handle lists           (BEWARE! Very Challenging)\n",
    "# This one is going to be a bit different from the others. Instead of using entire columns as\n",
    "# inputs/outputs, you will be using values, specifically, sequence or list values\n",
    "\n",
    "# Several columns have sequences as values. See for example:\n",
    "# df['Please select all of the following for which you have some experience']\n",
    "# or\n",
    "# df['Type 5 random (English) words'] \n",
    "\n",
    "# Write a function that handles these lists. First, it should take a separator, where\n",
    "# the user inputs what string should separate items in these lists (for example ';').\n",
    "# If the separator is None, it should automatically try several types of separators and\n",
    "# evaluate each separator by whether the length of the separated item matches a user\n",
    "# input value. \n",
    "\n",
    "# For example, the user input value for df['Type 5 random (English) words']\n",
    "# would be 5. The function would test several separators for each list (' ' or ', ' or ',')\n",
    "# until it finds a solution where the value is separated into a list of 5 items.\n",
    "\n",
    "# If it cannot find a solution that is equal to the target, it should find the separator\n",
    "# that has the closest number of separations to the target\n",
    "\n",
    "# If no input value is set, it should use the separator that results in the\n",
    "# greatest number of splits.\n",
    "\n",
    "# Also, in all cases, the function should return which separator was used. \n",
    "\n",
    "# Additionally, you should add an optional argument where the user can choose to return only\n",
    "# the length of the list in addition. (Sometimes we may only wish to get the length, consider\n",
    "# df['Do you strongly dislike the taste or texture of any of the following things?'] where\n",
    "# length of the sequence could be an measurement of whether someone is a picky eater!)\n",
    "\n",
    "# Finally, the user can input whether they want the value to be returned a separated\n",
    "# list, or as a string where the values are separated by a user defined string\n",
    "\n",
    "# HINT: You may want to create and use subfunctions for this function\n",
    "\n",
    "\n",
    "## Part H -- Simplify   (Challenging)\n",
    "# A lot of people put smartass answers into some of the open response questions, or they gave a\n",
    "# bit more detail than is useful. This is of course my fault for not being more specific with the\n",
    "# questions and controlling the output. Write a function that will detect whether a given string\n",
    "# value has another existing string value (from the same column) within it. For example, if one\n",
    "# value say \"green and white\", and \"white\" is another existing value in the column, it will replace\n",
    "# \"green and white\" with \"white\". There should be a \"tie\" argument where the user can choose between\n",
    "# 'alert' or 'remove' modes. If 'alert', if more than one value fits, (for example if both \"green\" and \n",
    "# \"white\" already exist in the column), it should print the index, both \"matching\" values, and\n",
    "# an instruction for the user to change it manually. If 'remove', it should replace the value with\n",
    "# a np.nan. Finally, as with other functions, this function should have an evaluate vs apply argument.\n",
    "\n",
    "## Part I -- Time Code       (Just a bit bumpy)\n",
    "# Two columns have date/time information in them, df.ix['Timestamp'] and df['What time is it right now?']\n",
    "# Write a function that will take these times and encode whether the survey was taken in morning,\n",
    "# afternoon, evening or night.\n",
    "# You may need to read about how to deal with datetime data: \n",
    "#http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
    "# or --> https://dateutil.readthedocs.io/en/stable/\n",
    "\n",
    "## Part J -- Uniqueness   (Challenging)\n",
    "# There are two columns that involve users to input a list of five words:\n",
    "# df['Name the first five animals you can think of'] and df['Type 5 random (English) words']\n",
    "# Think of a function that calculates how unique each word is that the user gave compared\n",
    "# to all words given by all users, and assign a single score of uniqueness for each row based on\n",
    "# the words given. How you do the scoring is up to you\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Part A -- Harmonize case  (Straightforward)\n",
    "# Many columns recieve string input. However, some users have chosen to use capital letters\n",
    "# while others have not. \n",
    "# See for example df[\"What color is the shirt/dress/upper-body-clothing you're wearing right now, if any?\"].unique()\n",
    "# Create a function that will make all string responses in a given column lowercase\n",
    "\n",
    "def harmonize_case(col):\n",
    "    ''' Given a pandas series or list, will change all rows with string values to lowercase\n",
    "    Outputs a sequence in the same format as input'''\n",
    "    col = deepcopy(col)\n",
    "    for i,val in enumerate(col):\n",
    "        if type(val) == str:\n",
    "            col[i] = val.lower()\n",
    "        else:\n",
    "            print('value %s at row %s is not a str, but a %s. Skipping...'%(val,i,type(val)))\n",
    "            continue\n",
    "    return col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo:\n",
    "col = df[\"What color is the shirt/dress/upper-body-clothing you're wearing right now, if any?\"]\n",
    "old_len = len(col.unique())\n",
    "ncol = harmonize_case(col)\n",
    "new_len = len(ncol.unique())\n",
    "\n",
    "print('old len is %s, new len is %s,'%(old_len,new_len),\n",
    "     'because %s entries became the same when case was harmonized'%(old_len - new_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Part B -- Character count   (Straightforward)\n",
    "# For the column 'Fill this text box with gibberish by mashing random keyboard keys', users \n",
    "# have entered a random number of string characters. We can count the number of characters\n",
    "# the users typed and use it as a measure of \"aggression\" or \"inner-stress\". Write a function\n",
    "# that will count the number of characters for each value in a columns\n",
    "\n",
    "def character_count(col):\n",
    "    '''given a pandas series or list, will output a new series or list with the character\n",
    "    count of string values'''\n",
    "    col = deepcopy(col)\n",
    "    for i,val in enumerate(col):\n",
    "        if type(val) == str:\n",
    "            col[i] = len(val)\n",
    "        else:\n",
    "            print('value %s at row %s is not a str, but a %s. Skipping...'%(val,i,type(val)))\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "col = df['Fill this text box with gibberish by mashing random keyboard keys']\n",
    "aggression = character_count(col)\n",
    "aggression[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Part C -- Handle NaNs    (Just a bit bumpy)\n",
    "# Many columns have NaNs, and depending on what program you use to analyze data, you may need\n",
    "# do address them. Write a function that handles the NaNs in a column. There should be an \n",
    "# argument where the user can define what they wish to do with the NaNs. They can either\n",
    "# remove all rows with a NaN from the column, or they can code the NaNs as something else.\n",
    "# You will obviously need a third argument where the user inputs what they want to code the\n",
    "# NaN as (example input could be 999 or np.nan or 'missing')\n",
    "\n",
    "def handle_NaNs(col,mode='remove',code=None):\n",
    "    \"\"\"takes a pandas Series or list as input. If mode is set to remove, will physically remove\n",
    "    all values (rows) with NaNs in them. If mode is set to \"encode\", will change NaNs to code.\n",
    "    Returns a pandas Series\n",
    "    \n",
    "    Note: remove will delete rows, mean dimensions of may be different from col\n",
    "     \"\"\"\n",
    "    \n",
    "    if mode != 'remove' and mode != 'encode':\n",
    "        raise ValueError('argument mode must be set to remove or encode')\n",
    "    \n",
    "    if mode == 'encode' and not code:\n",
    "        raise ReferenceError('if mode is set encode, argument code must be passed')\n",
    "    \n",
    "    col = pandas.Series(deepcopy(col))\n",
    "    if mode == 'remove':\n",
    "        o_len = len(col)\n",
    "        col.dropna(inplace=True)\n",
    "        n_len = len(col)\n",
    "        print('%s rows removed'%(o_len - n_len))\n",
    "    \n",
    "    elif mode == 'encode':\n",
    "        count = 0\n",
    "        for i,val in enumerate(col):\n",
    "            if not pandas.notnull(val):\n",
    "                col[i] = code\n",
    "                count = count+1\n",
    "        print('%s rows changed'%(count))\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "col = df['Enter your codename here']\n",
    "adjusted_subs = handle_NaNs(col,mode='encode',code='#Value Missing')\n",
    "adjusted_subs[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Part D -- Encode    (Just a bit bumpy)\n",
    "# Write a function that will take a dictionary as input. The dictionary should have column\n",
    "# values as keys and new (encoded) values as the corresponding dictionary values. For example,\n",
    "# input could be {Yes: 1, No: 0}. The function should apply the code to the column.\n",
    "# If the dictionary argument is set to None, the function should automatically encode unique\n",
    "# values with sequential integers.\n",
    "\n",
    "def encode(col, code_dict=None):\n",
    "    '''col is a pandas Series or list as input. Code_dict is a dict such that keys are entries\n",
    "    that exist in col, and values are new entries to replace the key, thus \"encoding\" the column.\n",
    "    If code_dict = None, will automatically encode unique values with sequential integers.\n",
    "    Returns pandas Series.'''\n",
    "    \n",
    "    col = pandas.Series(deepcopy(col))\n",
    "    net = []\n",
    "    if not code_dict:\n",
    "        code_dict = {}\n",
    "        for i,val in enumerate(col.unique()):\n",
    "            if pandas.notnull(val):\n",
    "                code_dict.update({val: i+1})\n",
    "            else: \n",
    "                code_dict.update({val: 0})\n",
    "    else:\n",
    "        if type(code_dict) != dict:\n",
    "            raise ValueError('code_dict must be a dictionary object')\n",
    "        \n",
    "    for i,val in enumerate(col):\n",
    "        if val in code_dict.keys():\n",
    "            col[i] = code_dict[val]\n",
    "        else:\n",
    "            net.append(val)\n",
    "    if len(net) > 0:\n",
    "        print('the following values were not assigned labels:')\n",
    "        for miss in net.unique():\n",
    "            print(miss)\n",
    "    \n",
    "    return col\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo 1\n",
    "col = df['Can you roll your tongue?']\n",
    "code = {'Yes': 3, 'What?': 2, 'No':1}\n",
    "tongue_coded = encode(col,code)\n",
    "tongue_coded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo 2\n",
    "col = df['What style of music do you most prefer?']\n",
    "music_coded = encode(col)\n",
    "music_coded[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Part E -- Binary encode      (Tricky)\n",
    "# Many columns have users choose from several different choices. See for example:\n",
    "# df['If you had to choose one, what would be your favorite type of beer?'].unique()\n",
    "# Create a function that will set one of those values to 1, and the rest to 0. The\n",
    "# value to be set as 1 should be specified by the user. I could use this for example\n",
    "# if I wanted to have a new variable called \"IPA Drinkers\".\n",
    "\n",
    "# The user can also input a list or Series, in which case all values within the list \n",
    "# are changed to 1, and everything else to 0. The function should call a specific error \n",
    "# if the user inputs a value that is not an existing value in the column. \n",
    "\n",
    "# BONUS: Add extra feature to allow the user to choose whether or not to leave NaNs as NaNs\n",
    "\n",
    "def binarize(col,binval,ignore_nan=False):\n",
    "    ''' Given input of a list or pandas Series, will change all entries of binval to 1\n",
    "    and all other entries to 0. If binval is a list, will change all entries matching \n",
    "    items in binval to 1, and all other entries as 0. If ignore_nan is True, NaNs will\n",
    "    be ignored and therefore set to 0. Otherwise, NaNs will remain as NaNs in the final\n",
    "    output. Outputs a pandas series'''\n",
    "    \n",
    "    col = deepcopy(pandas.Series(col))\n",
    "    u = col.unique()\n",
    "    \n",
    "    if not ignore_nan:\n",
    "        nanz= []\n",
    "        for i,val in enumerate(col):\n",
    "            if not pandas.notnull(val):\n",
    "                nanz.append(i)\n",
    "                \n",
    "    if type(binval) != str: # since str is subscriptable\n",
    "        try:\n",
    "            binval[0] # will fail if binval is not a subscriptable object\n",
    "            # Deal with typos in binval\n",
    "            for x in binval:\n",
    "                if x not in u:\n",
    "                    raise ValueError('%s was entered into binval, but %s is not a valid entry in this column'%(x,x))\n",
    "            # encode using list of values\n",
    "            for i,val in enumerate(col):\n",
    "                if val in binval:\n",
    "                    col[i] = 1\n",
    "                else:\n",
    "                    col[i] = 0\n",
    "        except:\n",
    "            # encode using single, non-str value\n",
    "            if binval not in u:\n",
    "                raise ValueError('%s was entered into binval, but %s is not a valid entry in this column'%(x,x))\n",
    "            col[col!=binval] = 0\n",
    "            col[col==binval] = 1\n",
    "    else:\n",
    "        # encode using str value\n",
    "        if binval not in u:\n",
    "            raise ValueError('%s was entered into binval, but %s is not a valid entry in this column'%(x,x))\n",
    "        col[col!=binval] = 0\n",
    "        col[col==binval] = 1\n",
    "    \n",
    "    # set NaNs values back to NaNs\n",
    "    if not ignore_nan:\n",
    "        for ind in nanz:\n",
    "            col[ind] = np.nan\n",
    "    \n",
    "    return col\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = df['If you had to choose one, what would be your favorite type of beer?']\n",
    "binval = 'Pale Ale or IPA'\n",
    "IPA_drinkers = binarize(col,binval)\n",
    "\n",
    "binval = ['Pale Ale or IPA','Amber, Red or Brown Ale']\n",
    "ale_drinkers = binarize(col,binval)\n",
    "\n",
    "print('IPA drinkers: \\n', IPA_drinkers[:10])\n",
    "print('\\n ale drinkers: \\n',ale_drinkers[:10])\n",
    "\n",
    "print('\\n Are all IPA drinkers ale drinkers? \\n',(IPA_drinkers == ale_drinkers)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Part F -- Purify int/floats        (Tricky)\n",
    "# Many columns have examples where users have input string when they were suppose to input \n",
    "# an integer or float. See for example: \n",
    "# df[\"How many romantic relationships have you been in that have lasted at least 6 months\"].unique()\n",
    "# Write a function that handles string inputs when they are supposed to be floats or ints. The function\n",
    "# should have two modes, evaluate and apply. If evaluate, the function will return all values (as well\n",
    "# as their index) that are not floats. This will let you evaluate whether you can fix these values\n",
    "# (either manually or with your encode function). If apply, the function will remove all non int/float\n",
    "# values and replace them with NaNs\n",
    "\n",
    "# If mode is set to apply, the function should return the modified column. If mode is set to evaluate,\n",
    "# the function should return the indices of the non-float/int values\n",
    "\n",
    "def purify_numbers(col,mode='evaluate'):\n",
    "    '''takes pandas Series or list. If mode is set to 'evaluate', will report the index of values\n",
    "    that are not number classes, and will return those indices. If set to 'apply', will return\n",
    "    col with non-floats/ints converted to NaNs'''\n",
    "    \n",
    "    if mode != 'evaluate' and mode != 'apply':\n",
    "        raise Warning('mode must be set to evaluate or apply,',\n",
    "                     'you set mode as %s. Running script in evaluate mode...'%(mode))\n",
    "        mode = 'evaluate'\n",
    "    \n",
    "    if mode == 'evaluate':\n",
    "        fail_idx = []\n",
    "    \n",
    "    col = deepcopy(col)\n",
    "    for i,val in enumerate(col):\n",
    "        try:\n",
    "            float(val)\n",
    "        except ValueError:\n",
    "            if mode == 'evaluate':\n",
    "                print('value %s at index %s is not a number class'%(val,i))\n",
    "                fail_idx.append(i)\n",
    "            else:\n",
    "                col[i] = np.nan\n",
    "    \n",
    "    if mode == 'evaluate':\n",
    "        if len(fail_idx) == 0:\n",
    "            print('all indices are numbers')\n",
    "        else:\n",
    "            return fail_idx\n",
    "    else:\n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "col = df['What are the chances (in percentage from 1-100) that the Dutch National team will win a EuroCup or WorldCup championship in the next 10 years?']\n",
    "fail_inds = purify_numbers(col)\n",
    "\n",
    "ncol = deepcopy(col)\n",
    "for i in fail_inds:\n",
    "    ncol[i] = ncol[i][:-1]\n",
    "\n",
    "print('\\nafter changing values using fail_inds...')\n",
    "\n",
    "purify_numbers(ncol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo 2\n",
    "col = df['How many romantic relationships have you been in that have lasted at least 6 months']\n",
    "fail_inds = purify_numbers(col)\n",
    "scrubbed_relationships = purify_numbers(col,mode='apply')\n",
    "scrubbed_relationships[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Part G -- Handle lists           (Challenging)\n",
    "# This one is going to be a bit different from the others. Instead of using entire columns as\n",
    "# inputs/outputs, you will be using values, specifically, sequence or list values\n",
    "\n",
    "# Several columns have sequences as values. See for example:\n",
    "# df['Please select all of the following for which you have some experience']\n",
    "# or\n",
    "# df['Type 5 random (English) words'] \n",
    "\n",
    "# Write a function that handles these lists. First, it should take a separator, where\n",
    "# the user inputs what string should separate items in these lists (for example ';').\n",
    "# If the separator is None, it should automatically try several types of separators and\n",
    "# evaluate each separator by whether the length of the separated item matches a user\n",
    "# input value. \n",
    "\n",
    "# For example, the user input value for df['Type 5 random (English) words']\n",
    "# would be 5. The function would test several separators for each list (' ' or ', ' or ',')\n",
    "# until it finds a solution where the value is separated into a list of 5 items.\n",
    "\n",
    "# If it cannot find a solution that is equal to the target, it should find the separator\n",
    "# that has the closest number of separations to the target\n",
    "\n",
    "# If no input value is set, it should use the separator that results in the\n",
    "# greatest number of splits.\n",
    "\n",
    "# Also, in all cases, the function should return which separator was used. \n",
    "\n",
    "# Additionally, you should add an optional argument where the user can choose to return only\n",
    "# the length of the list in addition. (Sometimes we may only wish to get the length, consider\n",
    "# df['Do you strongly dislike the taste or texture of any of the following things?'] where\n",
    "# length of the sequence could be an measurement of whether someone is a picky eater!)\n",
    "\n",
    "# Finally, the user can input whether they want the value to be returned a separated\n",
    "# list, or as a string where the values are separated by a user defined string\n",
    "\n",
    "\n",
    "# IM GOING TO HANDLE THIS WITH SUBFUNCTIONS, TO MAKE THE OVERALL READABILITY OF THE CODE \n",
    "# BETTER\n",
    "\n",
    "def handle_list(val,sep=None,target=None,out_type='list',out_sep=', ',len_only=False,verbose=True):\n",
    "    '''input is a string that needs to be split. If sep is specified, will try toseparate \n",
    "    string by specified sep. If sep = None, function will use multiple separators and \n",
    "    choose the one that separates the string to the length specified in target. If no\n",
    "    string succeeds, the separator that results to the closest length to target is chosen.\n",
    "    If no target is specified, function will choose the separator that returns the greatest\n",
    "    number of separations. \n",
    "    Output changes depending on arguments. If out_type set to list, function will output\n",
    "    a list. If set to str, function will output a str separated by out_sep. Finally, if\n",
    "    len_only is True, function will return only the length of the separated list.\n",
    "    If verbose set to False, script will not print output'''\n",
    "    \n",
    "    if out_type != 'list' and out_type != 'str':\n",
    "        raise ValueError(\"out_type must be set to 'list' or 'str'\")\n",
    "    \n",
    "    # Handle sep if sep is not a str\n",
    "    if sep:\n",
    "        if type(sep) != str:\n",
    "            raise TypeError('sep must must a str object, you entered a %s object'%(type(sep)))\n",
    "            \n",
    "    # make sure target is specified and spawn sep_list\n",
    "    else:\n",
    "        if target: \n",
    "            if type(target) != int:\n",
    "                raise ValueError('if sep is not specified, target must be set to an int')\n",
    "        sep_list = [', ',',','; ',';',' ']\n",
    "        # There's a more elegant way of doing this with regexp, but its a bit advanced for\n",
    "        # where we are in the course, so I'll just do it this way.\n",
    "    \n",
    "    val = deepcopy(val)\n",
    "    \n",
    "    # Perform separation in situations where sep is specified\n",
    "    if sep:\n",
    "        try:\n",
    "            val_list = val.split(sep)\n",
    "            sep_used = sep\n",
    "        except:\n",
    "            # if separator doesn't work\n",
    "            if verbose:\n",
    "                print('could not separate %s, of the %s class, using sep %s'%(val,type(val),sep))\n",
    "            sep_used = np.nan\n",
    "            nval = val\n",
    "        else:\n",
    "            if len_only:\n",
    "                nval = len(val_list)\n",
    "            else:\n",
    "                nval = construct_output(val_list,out_type,out_sep)\n",
    "    \n",
    "    # Perform iterative search through seps to find best separator      \n",
    "    else:\n",
    "        if target:\n",
    "            nval,sep_used = find_best_sep_target(val,sep_list,target,out_type,out_sep,len_only,verbose)\n",
    "        else:\n",
    "            nval,sep_used = find_best_sep_notarget(val,sep_list,out_type,out_sep,len_only,verbose)\n",
    "            \n",
    "        if verbose:\n",
    "            print('using %s as sep'%(sep_used))   \n",
    "        \n",
    "    return nval,sep_used\n",
    "\n",
    "\n",
    "    \n",
    "def find_best_sep_target(val,sep_list,target,out_type,out_sep,len_only,verbose):\n",
    "    result = False\n",
    "    x = 0\n",
    "    # find separator that matches target\n",
    "    while not result and x < len(sep_list):\n",
    "        sep = sep_list[x]\n",
    "        try:\n",
    "            val_list = val.split(sep)\n",
    "            if len(val_list) == target:\n",
    "                result = True\n",
    "            else:\n",
    "                x = x+1\n",
    "        except:\n",
    "            x = x+1\n",
    "                \n",
    "    if not result:\n",
    "        # if no separator found to match target\n",
    "        if verbose:\n",
    "            print('WARNING: could not find a valid parser for val %s'%(val))\n",
    "            print('Instead, searching for sep with the closest match to target...')\n",
    "        nval,sep_used = find_best_sep_notarget(val,sep_list,out_type,out_sep,len_only,target)\n",
    "    else:\n",
    "        if len_only:\n",
    "            nval = len(val_list)\n",
    "            sep_used = np.nan\n",
    "        else:\n",
    "            sep_used = sep_list[x]\n",
    "            nval = construct_output(val_list,out_type,out_sep)\n",
    "            \n",
    "    return nval,sep_used\n",
    "\n",
    "def find_best_sep_notarget(val,sep_list,out_type,out_sep,len_only,verbose,target=None):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for sep in sep_list:\n",
    "        try:\n",
    "            val_list = val.split(sep)\n",
    "            results.append(len(val_list))\n",
    "        except:\n",
    "            results.append(0)\n",
    "    \n",
    "    if target:\n",
    "        diff = []\n",
    "        for r in results:\n",
    "            adiff = abs(r - target)\n",
    "            diff.append(adiff)\n",
    "        best_ind = np.argmin(diff)\n",
    "     \n",
    "    else:\n",
    "        best_ind = np.argmax(results)\n",
    "    \n",
    "    sep_used = sep_list[best_ind]\n",
    "    \n",
    "    try:\n",
    "        val_list = val.split(sep_used)\n",
    "    except:\n",
    "        if verbose:\n",
    "            print('no possible separator found for %s, of the %s class'%(val,type(val)))\n",
    "        nval,sep_used = val,np.nan\n",
    "    else:\n",
    "        if len_only:\n",
    "            nval = len(val_list)\n",
    "        else:\n",
    "            nval = construct_output(val_list,out_type,out_sep)\n",
    "    \n",
    "    return nval,sep_used\n",
    "    \n",
    "    \n",
    "def construct_output(in_list,out_type,out_sep):\n",
    "    if out_type == 'list':\n",
    "        nval = in_list \n",
    "    else:\n",
    "        nval=''\n",
    "        for entry in in_list:\n",
    "            nval = nval+entry+out_sep\n",
    "    \n",
    "    return nval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo 1\n",
    "col = df['Please select all of the following for which you have some experience']\n",
    "for i,x in enumerate(col[:10]):\n",
    "    y,z = handle_list(x,sep=';',len_only=True)\n",
    "    print('subject %s programming experience = %s'%(i,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo 2\n",
    "col = df['Type 5 random (English) words']\n",
    "\n",
    "for i,x in enumerate(col[:10]):\n",
    "    print(i)\n",
    "    y,z = handle_list(x,target=5)\n",
    "    print(y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo 3\n",
    "col = df['Name the first five animals you can think of']\n",
    "\n",
    "for i,x in enumerate(col[:10]):\n",
    "    print(i)\n",
    "    y,z = handle_list(x,target=5,out_type='str',out_sep='/')\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Part H -- Simplify        (Challenging)\n",
    "# A lot of people put smartass answers into some of the open response questions, or they gave a\n",
    "# bit more detail than is useful. This is of course my fault for not being more specific with the\n",
    "# questions and controlling the output. Write a function that will detect whether a given string\n",
    "# value has another existing string value (from the same column) within it. For example, if one\n",
    "# value say \"green and white\", and \"white\" is another existing value in the column, it will replace\n",
    "# \"green and white\" with \"white\". There should be a \"tie\" argument where the user can choose between\n",
    "# 'alert' or 'remove' modes. If 'alert', if more than one value fits, (for example if both \"green\" and \n",
    "# \"white\" already exist in the column), it should print the index, both \"matching\" values, and\n",
    "# an instruction for the user to change it manually. If 'remove', it should replace the value with\n",
    "# a np.nan. Finally, as with other functions, this function should have an evaluate vs apply argument.\n",
    "\n",
    "def simplify(col, tie='alert', mode='evaluate',in_words=None):\n",
    "    '''\n",
    "    input should be a pandas Series or list. Function will search through entries in series and''\n",
    "    will make suggestions as to what changes can be made to better harmonize list entries. Function\n",
    "    works by checking if existing entries can be found within other entries. In case more than one\n",
    "    suggestion can be made, if tie is set to alert, the user will merely be alerted of the tie and\n",
    "    no changes will take place. If set to remove, the tied value will be set to NaN. \n",
    "    Output depends on mode. If mode set to evaluate, function will print suggestions and the will \n",
    "    return the index of the suggested items. If mode set to apply, function will make the\n",
    "    suggestions and return a pandas Series with suggestions made.\n",
    "    In_words can be a list of words that the function uses as a reference for simplification \n",
    "    '''\n",
    "    \n",
    "    if tie != 'alert' and tie != 'remove':\n",
    "        raise Warning('tie must be set to alert or remove. Users specified %s,'%(tie),\n",
    "                     'moving forward with tie set to alert')\n",
    "    \n",
    "    if mode != 'evaluate' and mode != 'apply':\n",
    "        raise Warning('mode must be set to evaluate or apply,',\n",
    "                     'you set mode as %s. Running script in evaluate mode...'%(mode))\n",
    "        mode = 'evaluate'\n",
    "    \n",
    "    #col = deepcopy(pandas.Series(col))\n",
    "    col = deepcopy(col)\n",
    "    \n",
    "    # initialize words\n",
    "    if in_words:\n",
    "        words=in_words\n",
    "    else:\n",
    "        words = list(col.unique())\n",
    "        for x,word in enumerate(words):\n",
    "            if type(word) != str:\n",
    "                words.remove(words[x])\n",
    "    \n",
    "    if mode == 'evaluate':\n",
    "        fail_inds = []\n",
    "    \n",
    "    for i,val in enumerate(col):\n",
    "        \n",
    "        if type(val) != str:\n",
    "            continue           # skip non-str entries\n",
    "        \n",
    "        # find partial matches\n",
    "        suggestions = []\n",
    "        for word in words:\n",
    "            if not word == val:\n",
    "                if word in val:\n",
    "                    suggestions.append(word)\n",
    "        \n",
    "        \n",
    "        if len(suggestions) == 0: # if none found, keep moving\n",
    "            continue\n",
    "        elif len(suggestions) == 1: # if one found, suggest it\n",
    "            if mode == 'evaluate':\n",
    "                print('suggestion found: perhaps replace %s at index %s with %s' %(val,i,suggestions[0]))\n",
    "                fail_inds.append(i)\n",
    "            else:\n",
    "                print('changing %s to %s'%(val,suggestions[0]))\n",
    "                col[i] = suggestions[0]\n",
    "                \n",
    "        else: # If there's a tie\n",
    "            if tie == 'alert':\n",
    "                print('the following suggestions were made or %s at index %s'%(val,i))\n",
    "                for sug in suggestions:\n",
    "                    print(sug)\n",
    "                print('please select the best option and change manually.',\n",
    "                     'or rerun with tie = remove to set ties to NaN')\n",
    "                fail_inds.append(i)\n",
    "            else:\n",
    "                print('tie found for %s.. setting to np.nan'%(val))\n",
    "                col[i] = np.nan\n",
    "    \n",
    "    if mode == 'evaluate':\n",
    "        return fail_inds\n",
    "    else:\n",
    "        return col\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "col = df['What color is the shirt/dress/upper-body-clothing you\\'re wearing right now, if any?']\n",
    "fail_inds = simplify(col)\n",
    "print('\\n')\n",
    "ncol = simplify(col,'remove','apply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Part I -- Time Code       (Just a bit bumpy)\n",
    "# Two columns have date/time information in them, df.ix['Timestamp'] and df['What time is it right now?']\n",
    "# Write a function that will take these times and encode whether the survey was taken in morning,\n",
    "# afternoon, evening or night.\n",
    "# You may need to read about how to deal with datetime data: \n",
    "#http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
    "# or --> https://dateutil.readthedocs.io/en/stable/\n",
    "\n",
    "from dateutil import parser\n",
    "\n",
    "def time_of_day(col):\n",
    "    '''function will take a pandas Series or list of datetimes. Function will return a new list or\n",
    "    Series indicating if the datetime corresponds to morning, afternoon, evening or night'''\n",
    "\n",
    "    col = deepcopy(col)\n",
    "    for i,val in enumerate(col): \n",
    "        try:\n",
    "            time = parser.parse(val)\n",
    "        except:\n",
    "            raise TypeError('could not parse %s at index %s, please make sure your inputs are datetimes'%(val,i))\n",
    "        if time.hour in range(0,6):\n",
    "            col[i] = 'night'\n",
    "        elif time.hour in range(6,12):\n",
    "            col[i] = 'morning'\n",
    "        elif time.hour in range(12,18):\n",
    "            col[i] = 'afternoon'\n",
    "        else:\n",
    "            col[i] = 'evening'\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "col = df['Timestamp']\n",
    "survey_time = time_of_day(col)\n",
    "survey_time[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Part J -- Uniqueness   (Challenging)\n",
    "# There are two columns that involve users to input a list of five words:\n",
    "# df['Name the first five animals you can think of'] and df['Type 5 random (English) words']\n",
    "# Think of a function that calculates how unique each word is that the user gave compared\n",
    "# to all words given by all users, and assign a single score of uniqueness for each row based on\n",
    "# the words given. How you do the scoring is up to you\n",
    "\n",
    "def uniqueness(col,seq=False,seq_sep=None,seq_target=None,score_bins=None):\n",
    "    \n",
    "    col = deepcopy(pandas.Series(col))\n",
    "    \n",
    "    # adjust default scoring parameters...\n",
    "    if score_bins:\n",
    "        if seq:\n",
    "            score_bins = 10\n",
    "        else:\n",
    "            score_bins = 5\n",
    "    \n",
    "    # First iteration: get word list\n",
    "    if not seq:\n",
    "        words = {}\n",
    "        for word in col.unique():\n",
    "            if type(word) == str and len(word) > 1:\n",
    "                if word in words.keys():\n",
    "                    words.update({word: words[word]+1})\n",
    "                else:\n",
    "                    words.update({word: 1})\n",
    "    else:\n",
    "        words = {}\n",
    "        for val in col:\n",
    "            val_list,jnk = handle_list(val,seq_sep,seq_target,verbose=False)\n",
    "            if type(val_list) != list:\n",
    "                continue\n",
    "            for word in val_list:\n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                if word in words.keys():\n",
    "                    words.update({word: words[word]+1})\n",
    "                else:\n",
    "                    words.update({word: 1})\n",
    "    \n",
    "    # for scoring\n",
    "    try:\n",
    "        jnk,values = np.histogram(list(words.values()),bins=score_bins)\n",
    "    except:\n",
    "        raise ValueError('score_bins is set too high. Reduce it!')\n",
    "    print(values)\n",
    "    \n",
    "    # Second iteration, calculate score\n",
    "    if not seq:\n",
    "        for i,val in enumerate(col):\n",
    "            if val in words.keys():\n",
    "                score = calc_word_score(words[val],values)\n",
    "                col[i] = score\n",
    "            else:\n",
    "                print('could not calculate score for index %s with value %s'%(i,val))\n",
    "                col[i] = np.nan\n",
    "    else:\n",
    "        for i,val in enumerate(col):\n",
    "            val_list,jnk = handle_list(val,seq_sep,seq_target,verbose=False)\n",
    "            \n",
    "            if type(val_list) != list:\n",
    "                print('could not calculate score for index %s with value %s'%(i,val))\n",
    "                col[i] = np.nan\n",
    "                \n",
    "            sub_score = []\n",
    "            if seq_target:\n",
    "                if len(val_list) > seq_target:\n",
    "                    print('index %s had more than %s words,'%(i,seq_target), \n",
    "                            'removing final word %s'%(val_list[-1]))\n",
    "                    val_list = val_list[:seq_target]\n",
    "            for word in val_list:\n",
    "                if word not in words.keys():\n",
    "                    continue\n",
    "                score = calc_word_score(words[word],values)\n",
    "                sub_score.append(score)\n",
    "            \n",
    "            col[i] = sum(sub_score)\n",
    "        \n",
    "        return col,list(words.keys())\n",
    "                \n",
    "    \n",
    "def calc_word_score(freq,values):\n",
    "        \n",
    "    binned = False\n",
    "    count = 0\n",
    "    while binned == False:\n",
    "        if freq <= values[count]:\n",
    "            binned = True\n",
    "        else:\n",
    "            count = count + 1\n",
    "        \n",
    "    score = len(values) - count\n",
    "\n",
    "    return score\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demo\n",
    "col = df['Name the first five animals you can think of']\n",
    "ncol,words = uniqueness(col,seq=True,seq_target=5,score_bins=2)\n",
    "ncol[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
